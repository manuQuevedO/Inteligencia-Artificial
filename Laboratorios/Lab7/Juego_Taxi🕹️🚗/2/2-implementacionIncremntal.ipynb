{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_q_table(q, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for i in range(q.shape[0]):\n",
    "            for j in range(q.shape[1]):\n",
    "                f.write(f\"state({i},{j}): {q[i, j]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Q(s,a)=Q(s,a)+Œ±(recompensa+Œ≥maxQ(s‚Ä≤,a‚Ä≤)‚àíQ(s,a))\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $Q(s,a)Q(s, a)Q(s,a)$ es el valor Q actual para el estado $sss$ y la acci√≥n $Œ±$.\n",
    "- $Œ±$ es la tasa de aprendizaje incremental.\n",
    "- $Œ≥$\\gammaŒ≥ es el factor de descuento (considera las recompensas futuras).\n",
    "- $max‚Å°Q(s‚Ä≤,a‚Ä≤)\\max Q(s', a')maxQ(s‚Ä≤,a‚Ä≤)$ es el valor m√°ximo esperado para el siguiente estado s‚Ä≤s's‚Ä≤ y todas las acciones a‚Ä≤a'a‚Ä≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(episodes, is_training=True, render=False, epsilon=0.1):\n",
    "    env = gym.make('Taxi-v3', render_mode='human' if render else None)\n",
    "\n",
    "    if is_training:\n",
    "        q = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "        visit_count = np.zeros_like(q)  # Contador de visitas para la implementaci√≥n incremental\n",
    "    else:\n",
    "        with open('taxi.pkl', 'rb') as f:\n",
    "            q = pickle.load(f)\n",
    "        visit_count = np.zeros_like(q)\n",
    "\n",
    "    discount_factor_g = 0.9\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    rewards_per_episode = np.zeros(episodes)\n",
    "\n",
    "    for i in range(episodes):\n",
    "        state = env.reset()[0]\n",
    "\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        rewards = 0\n",
    "\n",
    "        while not terminated and not truncated:\n",
    "            if is_training:\n",
    "                # Selecci√≥n de acci√≥n utilizando epsilon-greedy\n",
    "                if rng.random() < epsilon:\n",
    "                    action = env.action_space.sample()\n",
    "                else:\n",
    "                    action = np.argmax(q[state, :])\n",
    "            else:\n",
    "                action = np.argmax(q[state, :])\n",
    "\n",
    "            new_state, reward, terminated, truncated, _ = env.step(action)\n",
    "            rewards += reward\n",
    "\n",
    "            if is_training:\n",
    "                visit_count[state, action] += 1  # Incrementar el contador de visitas\n",
    "                alpha = 1 / visit_count[state, action]  # Tasa de aprendizaje incremental\n",
    "\n",
    "                # Actualizaci√≥n de Q usando la f√≥rmula de acci√≥n-valor incremental\n",
    "                q[state, action] += alpha * (\n",
    "                    reward + discount_factor_g * np.max(q[new_state, :]) - q[state, action]\n",
    "                )\n",
    "\n",
    "            state = new_state\n",
    "\n",
    "        epsilon = max(epsilon - 0.0001, 0)\n",
    "        rewards_per_episode[i] = rewards\n",
    "\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f'Episodio: {i + 1} - Recompensa: {rewards_per_episode[i]}')\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    # Guardar la tabla Q final en un archivo de texto\n",
    "    save_q_table(q, 'C:/Users/Manuel/Desktop/Septimo Semestre/Inteligencia Artificial/Laboratorios/Lab7/Juego_TaxiüïπÔ∏èüöó/2/q_table.txt')\n",
    "\n",
    "    if is_training:\n",
    "        with open(\"taxi.pkl\", \"wb\") as f:\n",
    "            pickle.dump(q, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodio: 50 - Recompensa: -254.0\n",
      "Episodio: 100 - Recompensa: -48.0\n",
      "Episodio: 150 - Recompensa: -24.0\n",
      "Episodio: 200 - Recompensa: -17.0\n",
      "Episodio: 250 - Recompensa: -38.0\n",
      "Episodio: 300 - Recompensa: -103.0\n",
      "Episodio: 350 - Recompensa: -182.0\n",
      "Episodio: 400 - Recompensa: -57.0\n",
      "Episodio: 450 - Recompensa: 12.0\n",
      "Episodio: 500 - Recompensa: 2.0\n",
      "Episodio: 550 - Recompensa: -26.0\n",
      "Episodio: 600 - Recompensa: -30.0\n",
      "Episodio: 650 - Recompensa: -37.0\n",
      "Episodio: 700 - Recompensa: 7.0\n",
      "Episodio: 750 - Recompensa: -34.0\n",
      "Episodio: 800 - Recompensa: -58.0\n",
      "Episodio: 850 - Recompensa: 0.0\n",
      "Episodio: 900 - Recompensa: 6.0\n",
      "Episodio: 950 - Recompensa: -64.0\n",
      "Episodio: 1000 - Recompensa: -33.0\n",
      "Episodio: 1050 - Recompensa: -49.0\n",
      "Episodio: 1100 - Recompensa: -79.0\n",
      "Episodio: 1150 - Recompensa: -90.0\n",
      "Episodio: 1200 - Recompensa: -25.0\n",
      "Episodio: 1250 - Recompensa: -18.0\n",
      "Episodio: 1300 - Recompensa: -71.0\n",
      "Episodio: 1350 - Recompensa: -30.0\n",
      "Episodio: 1400 - Recompensa: -45.0\n",
      "Episodio: 1450 - Recompensa: 12.0\n",
      "Episodio: 1500 - Recompensa: 3.0\n",
      "Episodio: 1550 - Recompensa: -27.0\n",
      "Episodio: 1600 - Recompensa: -66.0\n",
      "Episodio: 1650 - Recompensa: 7.0\n",
      "Episodio: 1700 - Recompensa: -68.0\n",
      "Episodio: 1750 - Recompensa: 11.0\n",
      "Episodio: 1800 - Recompensa: 13.0\n",
      "Episodio: 1850 - Recompensa: -13.0\n",
      "Episodio: 1900 - Recompensa: 7.0\n",
      "Episodio: 1950 - Recompensa: -34.0\n",
      "Episodio: 2000 - Recompensa: -90.0\n",
      "Episodio: 2050 - Recompensa: 8.0\n",
      "Episodio: 2100 - Recompensa: -30.0\n",
      "Episodio: 2150 - Recompensa: -47.0\n",
      "Episodio: 2200 - Recompensa: 4.0\n",
      "Episodio: 2250 - Recompensa: 11.0\n",
      "Episodio: 2300 - Recompensa: -79.0\n",
      "Episodio: 2350 - Recompensa: 10.0\n",
      "Episodio: 2400 - Recompensa: -8.0\n",
      "Episodio: 2450 - Recompensa: 11.0\n",
      "Episodio: 2500 - Recompensa: 9.0\n",
      "Episodio: 2550 - Recompensa: 12.0\n",
      "Episodio: 2600 - Recompensa: -16.0\n",
      "Episodio: 2650 - Recompensa: 11.0\n",
      "Episodio: 2700 - Recompensa: 6.0\n",
      "Episodio: 2750 - Recompensa: 14.0\n",
      "Episodio: 2800 - Recompensa: 6.0\n",
      "Episodio: 2850 - Recompensa: 5.0\n",
      "Episodio: 2900 - Recompensa: -15.0\n",
      "Episodio: 2950 - Recompensa: -32.0\n",
      "Episodio: 3000 - Recompensa: 8.0\n",
      "Episodio: 3050 - Recompensa: -35.0\n",
      "Episodio: 3100 - Recompensa: 10.0\n",
      "Episodio: 3150 - Recompensa: -4.0\n",
      "Episodio: 3200 - Recompensa: -22.0\n",
      "Episodio: 3250 - Recompensa: -112.0\n",
      "Episodio: 3300 - Recompensa: -32.0\n",
      "Episodio: 3350 - Recompensa: -17.0\n",
      "Episodio: 3400 - Recompensa: 9.0\n",
      "Episodio: 3450 - Recompensa: -28.0\n",
      "Episodio: 3500 - Recompensa: 1.0\n",
      "Episodio: 3550 - Recompensa: -56.0\n",
      "Episodio: 3600 - Recompensa: -28.0\n",
      "Episodio: 3650 - Recompensa: 13.0\n",
      "Episodio: 3700 - Recompensa: -12.0\n",
      "Episodio: 3750 - Recompensa: -59.0\n",
      "Episodio: 3800 - Recompensa: 10.0\n",
      "Episodio: 3850 - Recompensa: 1.0\n",
      "Episodio: 3900 - Recompensa: 3.0\n",
      "Episodio: 3950 - Recompensa: -4.0\n",
      "Episodio: 4000 - Recompensa: 11.0\n",
      "Episodio: 4050 - Recompensa: -31.0\n",
      "Episodio: 4100 - Recompensa: 9.0\n",
      "Episodio: 4150 - Recompensa: 5.0\n",
      "Episodio: 4200 - Recompensa: -9.0\n",
      "Episodio: 4250 - Recompensa: 3.0\n",
      "Episodio: 4300 - Recompensa: -13.0\n",
      "Episodio: 4350 - Recompensa: -15.0\n",
      "Episodio: 4400 - Recompensa: 0.0\n",
      "Episodio: 4450 - Recompensa: -5.0\n",
      "Episodio: 4500 - Recompensa: 11.0\n",
      "Episodio: 4550 - Recompensa: 14.0\n",
      "Episodio: 4600 - Recompensa: 8.0\n",
      "Episodio: 4650 - Recompensa: -30.0\n",
      "Episodio: 4700 - Recompensa: -43.0\n",
      "Episodio: 4750 - Recompensa: 6.0\n",
      "Episodio: 4800 - Recompensa: 11.0\n",
      "Episodio: 4850 - Recompensa: -3.0\n",
      "Episodio: 4900 - Recompensa: 10.0\n",
      "Episodio: 4950 - Recompensa: -31.0\n",
      "Episodio: 5000 - Recompensa: -50.0\n",
      "Episodio: 5050 - Recompensa: -48.0\n",
      "Episodio: 5100 - Recompensa: -58.0\n",
      "Episodio: 5150 - Recompensa: 4.0\n",
      "Episodio: 5200 - Recompensa: 5.0\n",
      "Episodio: 5250 - Recompensa: -7.0\n",
      "Episodio: 5300 - Recompensa: -52.0\n",
      "Episodio: 5350 - Recompensa: 1.0\n",
      "Episodio: 5400 - Recompensa: 7.0\n",
      "Episodio: 5450 - Recompensa: -3.0\n",
      "Episodio: 5500 - Recompensa: -5.0\n",
      "Episodio: 5550 - Recompensa: -1.0\n",
      "Episodio: 5600 - Recompensa: 8.0\n",
      "Episodio: 5650 - Recompensa: -32.0\n",
      "Episodio: 5700 - Recompensa: -6.0\n",
      "Episodio: 5750 - Recompensa: -6.0\n",
      "Episodio: 5800 - Recompensa: -6.0\n",
      "Episodio: 5850 - Recompensa: 0.0\n",
      "Episodio: 5900 - Recompensa: 11.0\n",
      "Episodio: 5950 - Recompensa: -26.0\n",
      "Episodio: 6000 - Recompensa: 11.0\n",
      "Episodio: 6050 - Recompensa: -8.0\n",
      "Episodio: 6100 - Recompensa: 8.0\n",
      "Episodio: 6150 - Recompensa: 5.0\n",
      "Episodio: 6200 - Recompensa: -10.0\n",
      "Episodio: 6250 - Recompensa: -58.0\n",
      "Episodio: 6300 - Recompensa: 13.0\n",
      "Episodio: 6350 - Recompensa: 12.0\n",
      "Episodio: 6400 - Recompensa: 1.0\n",
      "Episodio: 6450 - Recompensa: -19.0\n",
      "Episodio: 6500 - Recompensa: -1.0\n",
      "Episodio: 6550 - Recompensa: -62.0\n",
      "Episodio: 6600 - Recompensa: -9.0\n",
      "Episodio: 6650 - Recompensa: 8.0\n",
      "Episodio: 6700 - Recompensa: 10.0\n",
      "Episodio: 6750 - Recompensa: 6.0\n",
      "Episodio: 6800 - Recompensa: 7.0\n",
      "Episodio: 6850 - Recompensa: 12.0\n",
      "Episodio: 6900 - Recompensa: 12.0\n",
      "Episodio: 6950 - Recompensa: 2.0\n",
      "Episodio: 7000 - Recompensa: -21.0\n",
      "Episodio: 7050 - Recompensa: -28.0\n",
      "Episodio: 7100 - Recompensa: 6.0\n",
      "Episodio: 7150 - Recompensa: -17.0\n",
      "Episodio: 7200 - Recompensa: -3.0\n",
      "Episodio: 7250 - Recompensa: 0.0\n",
      "Episodio: 7300 - Recompensa: -20.0\n",
      "Episodio: 7350 - Recompensa: 12.0\n",
      "Episodio: 7400 - Recompensa: 6.0\n",
      "Episodio: 7450 - Recompensa: -16.0\n",
      "Episodio: 7500 - Recompensa: -5.0\n",
      "Episodio: 7550 - Recompensa: 13.0\n",
      "Episodio: 7600 - Recompensa: -20.0\n",
      "Episodio: 7650 - Recompensa: 14.0\n",
      "Episodio: 7700 - Recompensa: -9.0\n",
      "Episodio: 7750 - Recompensa: 10.0\n",
      "Episodio: 7800 - Recompensa: 0.0\n",
      "Episodio: 7850 - Recompensa: -3.0\n",
      "Episodio: 7900 - Recompensa: -81.0\n",
      "Episodio: 7950 - Recompensa: -14.0\n",
      "Episodio: 8000 - Recompensa: 5.0\n",
      "Episodio: 8050 - Recompensa: -37.0\n",
      "Episodio: 8100 - Recompensa: 12.0\n",
      "Episodio: 8150 - Recompensa: 14.0\n",
      "Episodio: 8200 - Recompensa: -15.0\n",
      "Episodio: 8250 - Recompensa: -50.0\n",
      "Episodio: 8300 - Recompensa: 7.0\n",
      "Episodio: 8350 - Recompensa: -20.0\n",
      "Episodio: 8400 - Recompensa: 7.0\n",
      "Episodio: 8450 - Recompensa: 0.0\n",
      "Episodio: 8500 - Recompensa: 11.0\n",
      "Episodio: 8550 - Recompensa: -9.0\n",
      "Episodio: 8600 - Recompensa: -3.0\n",
      "Episodio: 8650 - Recompensa: 10.0\n",
      "Episodio: 8700 - Recompensa: -31.0\n",
      "Episodio: 8750 - Recompensa: -31.0\n",
      "Episodio: 8800 - Recompensa: 15.0\n",
      "Episodio: 8850 - Recompensa: 11.0\n",
      "Episodio: 8900 - Recompensa: 9.0\n",
      "Episodio: 8950 - Recompensa: -47.0\n",
      "Episodio: 9000 - Recompensa: 1.0\n",
      "Episodio: 9050 - Recompensa: 12.0\n",
      "Episodio: 9100 - Recompensa: -12.0\n",
      "Episodio: 9150 - Recompensa: 0.0\n",
      "Episodio: 9200 - Recompensa: 0.0\n",
      "Episodio: 9250 - Recompensa: -14.0\n",
      "Episodio: 9300 - Recompensa: 12.0\n",
      "Episodio: 9350 - Recompensa: 10.0\n",
      "Episodio: 9400 - Recompensa: 15.0\n",
      "Episodio: 9450 - Recompensa: 10.0\n",
      "Episodio: 9500 - Recompensa: 0.0\n",
      "Episodio: 9550 - Recompensa: -7.0\n",
      "Episodio: 9600 - Recompensa: -10.0\n",
      "Episodio: 9650 - Recompensa: 1.0\n",
      "Episodio: 9700 - Recompensa: 7.0\n",
      "Episodio: 9750 - Recompensa: -17.0\n",
      "Episodio: 9800 - Recompensa: -5.0\n",
      "Episodio: 9850 - Recompensa: 3.0\n",
      "Episodio: 9900 - Recompensa: -17.0\n",
      "Episodio: 9950 - Recompensa: 6.0\n",
      "Episodio: 10000 - Recompensa: -6.0\n",
      "Episodio: 10050 - Recompensa: 13.0\n",
      "Episodio: 10100 - Recompensa: -54.0\n",
      "Episodio: 10150 - Recompensa: -36.0\n",
      "Episodio: 10200 - Recompensa: 11.0\n",
      "Episodio: 10250 - Recompensa: 0.0\n",
      "Episodio: 10300 - Recompensa: 11.0\n",
      "Episodio: 10350 - Recompensa: 10.0\n",
      "Episodio: 10400 - Recompensa: 8.0\n",
      "Episodio: 10450 - Recompensa: 1.0\n",
      "Episodio: 10500 - Recompensa: 7.0\n",
      "Episodio: 10550 - Recompensa: 10.0\n",
      "Episodio: 10600 - Recompensa: -29.0\n",
      "Episodio: 10650 - Recompensa: 6.0\n",
      "Episodio: 10700 - Recompensa: 12.0\n",
      "Episodio: 10750 - Recompensa: 10.0\n",
      "Episodio: 10800 - Recompensa: 3.0\n",
      "Episodio: 10850 - Recompensa: 13.0\n",
      "Episodio: 10900 - Recompensa: 8.0\n",
      "Episodio: 10950 - Recompensa: 11.0\n",
      "Episodio: 11000 - Recompensa: 3.0\n",
      "Episodio: 11050 - Recompensa: 8.0\n",
      "Episodio: 11100 - Recompensa: -11.0\n",
      "Episodio: 11150 - Recompensa: 10.0\n",
      "Episodio: 11200 - Recompensa: 10.0\n",
      "Episodio: 11250 - Recompensa: 10.0\n",
      "Episodio: 11300 - Recompensa: 9.0\n",
      "Episodio: 11350 - Recompensa: -27.0\n",
      "Episodio: 11400 - Recompensa: 9.0\n",
      "Episodio: 11450 - Recompensa: -2.0\n",
      "Episodio: 11500 - Recompensa: 8.0\n",
      "Episodio: 11550 - Recompensa: 12.0\n",
      "Episodio: 11600 - Recompensa: 11.0\n",
      "Episodio: 11650 - Recompensa: -2.0\n",
      "Episodio: 11700 - Recompensa: 15.0\n",
      "Episodio: 11750 - Recompensa: -11.0\n",
      "Episodio: 11800 - Recompensa: 1.0\n",
      "Episodio: 11850 - Recompensa: 6.0\n",
      "Episodio: 11900 - Recompensa: 3.0\n",
      "Episodio: 11950 - Recompensa: -24.0\n",
      "Episodio: 12000 - Recompensa: 10.0\n",
      "Episodio: 12050 - Recompensa: -21.0\n",
      "Episodio: 12100 - Recompensa: -18.0\n",
      "Episodio: 12150 - Recompensa: -37.0\n",
      "Episodio: 12200 - Recompensa: -104.0\n",
      "Episodio: 12250 - Recompensa: 11.0\n",
      "Episodio: 12300 - Recompensa: 9.0\n",
      "Episodio: 12350 - Recompensa: -19.0\n",
      "Episodio: 12400 - Recompensa: -68.0\n",
      "Episodio: 12450 - Recompensa: 3.0\n",
      "Episodio: 12500 - Recompensa: 9.0\n",
      "Episodio: 12550 - Recompensa: 8.0\n",
      "Episodio: 12600 - Recompensa: -26.0\n",
      "Episodio: 12650 - Recompensa: 14.0\n",
      "Episodio: 12700 - Recompensa: 10.0\n",
      "Episodio: 12750 - Recompensa: 14.0\n",
      "Episodio: 12800 - Recompensa: 4.0\n",
      "Episodio: 12850 - Recompensa: -16.0\n",
      "Episodio: 12900 - Recompensa: 1.0\n",
      "Episodio: 12950 - Recompensa: 5.0\n",
      "Episodio: 13000 - Recompensa: 9.0\n",
      "Episodio: 13050 - Recompensa: 2.0\n",
      "Episodio: 13100 - Recompensa: 12.0\n",
      "Episodio: 13150 - Recompensa: -12.0\n",
      "Episodio: 13200 - Recompensa: 10.0\n",
      "Episodio: 13250 - Recompensa: 9.0\n",
      "Episodio: 13300 - Recompensa: 4.0\n",
      "Episodio: 13350 - Recompensa: 6.0\n",
      "Episodio: 13400 - Recompensa: 13.0\n",
      "Episodio: 13450 - Recompensa: 15.0\n",
      "Episodio: 13500 - Recompensa: -1.0\n",
      "Episodio: 13550 - Recompensa: -41.0\n",
      "Episodio: 13600 - Recompensa: 6.0\n",
      "Episodio: 13650 - Recompensa: -9.0\n",
      "Episodio: 13700 - Recompensa: 9.0\n",
      "Episodio: 13750 - Recompensa: -79.0\n",
      "Episodio: 13800 - Recompensa: -51.0\n",
      "Episodio: 13850 - Recompensa: 10.0\n",
      "Episodio: 13900 - Recompensa: 10.0\n",
      "Episodio: 13950 - Recompensa: 5.0\n",
      "Episodio: 14000 - Recompensa: 10.0\n",
      "Episodio: 14050 - Recompensa: -12.0\n",
      "Episodio: 14100 - Recompensa: -51.0\n",
      "Episodio: 14150 - Recompensa: 6.0\n",
      "Episodio: 14200 - Recompensa: 11.0\n",
      "Episodio: 14250 - Recompensa: 3.0\n",
      "Episodio: 14300 - Recompensa: 3.0\n",
      "Episodio: 14350 - Recompensa: 1.0\n",
      "Episodio: 14400 - Recompensa: 3.0\n",
      "Episodio: 14450 - Recompensa: -21.0\n",
      "Episodio: 14500 - Recompensa: -38.0\n",
      "Episodio: 14550 - Recompensa: 11.0\n",
      "Episodio: 14600 - Recompensa: 4.0\n",
      "Episodio: 14650 - Recompensa: 4.0\n",
      "Episodio: 14700 - Recompensa: 13.0\n",
      "Episodio: 14750 - Recompensa: 11.0\n",
      "Episodio: 14800 - Recompensa: -56.0\n",
      "Episodio: 14850 - Recompensa: 10.0\n",
      "Episodio: 14900 - Recompensa: 9.0\n",
      "Episodio: 14950 - Recompensa: 10.0\n",
      "Episodio: 15000 - Recompensa: 7.0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl kernel se bloque√≥ al ejecutar c√≥digo en la celda actual o en una celda anterior. \n",
      "\u001b[1;31mRevise el c√≥digo de las celdas para identificar una posible causa del error. \n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqu√≠</a> para obtener m√°s informaci√≥n. \n",
      "\u001b[1;31mVea Jupyter <a href='command:jupyter.viewOutput'>log</a> para obtener m√°s detalles."
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    run(15000, is_training=True, render=False, epsilon=0.1)  # Primero entrena el modelo\n",
    "    run(6, is_training=False, render=True, epsilon=0.1)  # Luego usa el modelo entrenado con renderizaci√≥n\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
