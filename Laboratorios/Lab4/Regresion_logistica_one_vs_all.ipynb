{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el laboratorio se hizo uso del para entrenar el modelo de **Regresion Logistica one vs all** aplicando regularizacion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se importo todas las librerias necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizando la libreria os para manejos de directorios\n",
    "import os\n",
    "\n",
    "# Computacion vectorial y cientifica para python\n",
    "import numpy as np  \n",
    "\n",
    "#importamos pandas para el manejo del dataset, y separarlos dentro de una matriz\n",
    "import pandas as pd\n",
    "\n",
    "#esta tabulate nos sirve para hacer tablas\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Librerias para graficación (trazado de gráficos)\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D  # -> Necesario para graficar superficies 3D\n",
    "\n",
    "#Para separa el 20% y 80%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modulo de optimizacion en scipy\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos del dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>Feature_10</th>\n",
       "      <th>Feature_11</th>\n",
       "      <th>Feature_12</th>\n",
       "      <th>Feature_13</th>\n",
       "      <th>Feature_14</th>\n",
       "      <th>Feature_15</th>\n",
       "      <th>Feature_16</th>\n",
       "      <th>Feature_17</th>\n",
       "      <th>Feature_18</th>\n",
       "      <th>Feature_19</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.989</td>\n",
       "      <td>0.933</td>\n",
       "      <td>7.066</td>\n",
       "      <td>7.578</td>\n",
       "      <td>6.594</td>\n",
       "      <td>2.849</td>\n",
       "      <td>4.931</td>\n",
       "      <td>72.072</td>\n",
       "      <td>24.617</td>\n",
       "      <td>142.936</td>\n",
       "      <td>74.081</td>\n",
       "      <td>105.701</td>\n",
       "      <td>54.521</td>\n",
       "      <td>32.617</td>\n",
       "      <td>121.537</td>\n",
       "      <td>25.751</td>\n",
       "      <td>144.337</td>\n",
       "      <td>69.595</td>\n",
       "      <td>41.101</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997</td>\n",
       "      <td>0.478</td>\n",
       "      <td>7.662</td>\n",
       "      <td>8.635</td>\n",
       "      <td>3.066</td>\n",
       "      <td>4.509</td>\n",
       "      <td>1.436</td>\n",
       "      <td>85.700</td>\n",
       "      <td>39.412</td>\n",
       "      <td>37.528</td>\n",
       "      <td>117.419</td>\n",
       "      <td>87.170</td>\n",
       "      <td>108.446</td>\n",
       "      <td>56.649</td>\n",
       "      <td>71.172</td>\n",
       "      <td>113.226</td>\n",
       "      <td>101.245</td>\n",
       "      <td>60.219</td>\n",
       "      <td>118.244</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.347</td>\n",
       "      <td>0.631</td>\n",
       "      <td>5.491</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.020</td>\n",
       "      <td>7.220</td>\n",
       "      <td>8.970</td>\n",
       "      <td>40.162</td>\n",
       "      <td>20.028</td>\n",
       "      <td>141.028</td>\n",
       "      <td>63.459</td>\n",
       "      <td>63.072</td>\n",
       "      <td>100.683</td>\n",
       "      <td>67.985</td>\n",
       "      <td>146.706</td>\n",
       "      <td>126.889</td>\n",
       "      <td>30.212</td>\n",
       "      <td>77.758</td>\n",
       "      <td>97.303</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.191</td>\n",
       "      <td>0.138</td>\n",
       "      <td>8.315</td>\n",
       "      <td>8.823</td>\n",
       "      <td>1.375</td>\n",
       "      <td>1.894</td>\n",
       "      <td>6.507</td>\n",
       "      <td>95.557</td>\n",
       "      <td>114.442</td>\n",
       "      <td>21.842</td>\n",
       "      <td>100.862</td>\n",
       "      <td>112.891</td>\n",
       "      <td>28.602</td>\n",
       "      <td>94.809</td>\n",
       "      <td>93.514</td>\n",
       "      <td>106.238</td>\n",
       "      <td>85.042</td>\n",
       "      <td>135.045</td>\n",
       "      <td>46.371</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.822</td>\n",
       "      <td>0.587</td>\n",
       "      <td>9.642</td>\n",
       "      <td>3.389</td>\n",
       "      <td>7.036</td>\n",
       "      <td>0.379</td>\n",
       "      <td>8.303</td>\n",
       "      <td>37.211</td>\n",
       "      <td>92.917</td>\n",
       "      <td>90.042</td>\n",
       "      <td>48.364</td>\n",
       "      <td>104.354</td>\n",
       "      <td>56.836</td>\n",
       "      <td>49.982</td>\n",
       "      <td>143.241</td>\n",
       "      <td>22.332</td>\n",
       "      <td>115.821</td>\n",
       "      <td>116.677</td>\n",
       "      <td>65.306</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33995</th>\n",
       "      <td>0.104</td>\n",
       "      <td>0.740</td>\n",
       "      <td>5.090</td>\n",
       "      <td>3.088</td>\n",
       "      <td>4.022</td>\n",
       "      <td>4.409</td>\n",
       "      <td>5.530</td>\n",
       "      <td>36.267</td>\n",
       "      <td>21.839</td>\n",
       "      <td>29.266</td>\n",
       "      <td>134.754</td>\n",
       "      <td>93.286</td>\n",
       "      <td>27.186</td>\n",
       "      <td>83.462</td>\n",
       "      <td>149.579</td>\n",
       "      <td>121.823</td>\n",
       "      <td>52.469</td>\n",
       "      <td>33.511</td>\n",
       "      <td>125.488</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33996</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.336</td>\n",
       "      <td>8.493</td>\n",
       "      <td>2.797</td>\n",
       "      <td>4.917</td>\n",
       "      <td>2.596</td>\n",
       "      <td>52.761</td>\n",
       "      <td>128.492</td>\n",
       "      <td>28.130</td>\n",
       "      <td>60.806</td>\n",
       "      <td>130.509</td>\n",
       "      <td>98.104</td>\n",
       "      <td>80.707</td>\n",
       "      <td>71.781</td>\n",
       "      <td>102.514</td>\n",
       "      <td>22.143</td>\n",
       "      <td>25.147</td>\n",
       "      <td>59.258</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33997</th>\n",
       "      <td>0.063</td>\n",
       "      <td>0.047</td>\n",
       "      <td>4.193</td>\n",
       "      <td>9.407</td>\n",
       "      <td>9.135</td>\n",
       "      <td>4.721</td>\n",
       "      <td>9.239</td>\n",
       "      <td>65.275</td>\n",
       "      <td>102.710</td>\n",
       "      <td>110.346</td>\n",
       "      <td>99.009</td>\n",
       "      <td>29.231</td>\n",
       "      <td>27.819</td>\n",
       "      <td>60.771</td>\n",
       "      <td>133.133</td>\n",
       "      <td>60.714</td>\n",
       "      <td>112.101</td>\n",
       "      <td>71.815</td>\n",
       "      <td>129.031</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33998</th>\n",
       "      <td>0.488</td>\n",
       "      <td>0.704</td>\n",
       "      <td>8.163</td>\n",
       "      <td>6.592</td>\n",
       "      <td>8.513</td>\n",
       "      <td>3.483</td>\n",
       "      <td>9.719</td>\n",
       "      <td>106.643</td>\n",
       "      <td>106.092</td>\n",
       "      <td>69.872</td>\n",
       "      <td>77.747</td>\n",
       "      <td>119.959</td>\n",
       "      <td>116.401</td>\n",
       "      <td>35.926</td>\n",
       "      <td>134.955</td>\n",
       "      <td>70.275</td>\n",
       "      <td>55.803</td>\n",
       "      <td>41.895</td>\n",
       "      <td>148.825</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33999</th>\n",
       "      <td>0.705</td>\n",
       "      <td>0.860</td>\n",
       "      <td>8.513</td>\n",
       "      <td>6.119</td>\n",
       "      <td>0.990</td>\n",
       "      <td>1.204</td>\n",
       "      <td>4.124</td>\n",
       "      <td>45.950</td>\n",
       "      <td>48.826</td>\n",
       "      <td>82.378</td>\n",
       "      <td>99.239</td>\n",
       "      <td>99.952</td>\n",
       "      <td>67.727</td>\n",
       "      <td>148.958</td>\n",
       "      <td>110.333</td>\n",
       "      <td>111.488</td>\n",
       "      <td>117.117</td>\n",
       "      <td>102.160</td>\n",
       "      <td>72.230</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
       "0          0.989      0.933      7.066      7.578      6.594      2.849   \n",
       "1          0.997      0.478      7.662      8.635      3.066      4.509   \n",
       "2          0.347      0.631      5.491      0.754      0.020      7.220   \n",
       "3          0.191      0.138      8.315      8.823      1.375      1.894   \n",
       "4          0.822      0.587      9.642      3.389      7.036      0.379   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "33995      0.104      0.740      5.090      3.088      4.022      4.409   \n",
       "33996      0.869      0.559      0.336      8.493      2.797      4.917   \n",
       "33997      0.063      0.047      4.193      9.407      9.135      4.721   \n",
       "33998      0.488      0.704      8.163      6.592      8.513      3.483   \n",
       "33999      0.705      0.860      8.513      6.119      0.990      1.204   \n",
       "\n",
       "       Feature_7  Feature_8  Feature_9  Feature_10  Feature_11  Feature_12  \\\n",
       "0          4.931     72.072     24.617     142.936      74.081     105.701   \n",
       "1          1.436     85.700     39.412      37.528     117.419      87.170   \n",
       "2          8.970     40.162     20.028     141.028      63.459      63.072   \n",
       "3          6.507     95.557    114.442      21.842     100.862     112.891   \n",
       "4          8.303     37.211     92.917      90.042      48.364     104.354   \n",
       "...          ...        ...        ...         ...         ...         ...   \n",
       "33995      5.530     36.267     21.839      29.266     134.754      93.286   \n",
       "33996      2.596     52.761    128.492      28.130      60.806     130.509   \n",
       "33997      9.239     65.275    102.710     110.346      99.009      29.231   \n",
       "33998      9.719    106.643    106.092      69.872      77.747     119.959   \n",
       "33999      4.124     45.950     48.826      82.378      99.239      99.952   \n",
       "\n",
       "       Feature_13  Feature_14  Feature_15  Feature_16  Feature_17  Feature_18  \\\n",
       "0          54.521      32.617     121.537      25.751     144.337      69.595   \n",
       "1         108.446      56.649      71.172     113.226     101.245      60.219   \n",
       "2         100.683      67.985     146.706     126.889      30.212      77.758   \n",
       "3          28.602      94.809      93.514     106.238      85.042     135.045   \n",
       "4          56.836      49.982     143.241      22.332     115.821     116.677   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "33995      27.186      83.462     149.579     121.823      52.469      33.511   \n",
       "33996      98.104      80.707      71.781     102.514      22.143      25.147   \n",
       "33997      27.819      60.771     133.133      60.714     112.101      71.815   \n",
       "33998     116.401      35.926     134.955      70.275      55.803      41.895   \n",
       "33999      67.727     148.958     110.333     111.488     117.117     102.160   \n",
       "\n",
       "       Feature_19  Class  \n",
       "0          41.101    1.0  \n",
       "1         118.244    0.0  \n",
       "2          97.303    4.0  \n",
       "3          46.371    2.0  \n",
       "4          65.306    0.0  \n",
       "...           ...    ...  \n",
       "33995     125.488    4.0  \n",
       "33996      59.258    2.0  \n",
       "33997     129.031    0.0  \n",
       "33998     148.825    2.0  \n",
       "33999      72.230    2.0  \n",
       "\n",
       "[34000 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Haciendo uso de la libreria pandas para leer el dataset, delimitado por \",\"\n",
    "df = pd.read_csv('Reuters Newswire Topics Dataset.csv', delimiter=',')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>Type_of_Loan</th>\n",
       "      <th>...</th>\n",
       "      <th>Credit_Mix</th>\n",
       "      <th>Outstanding_Debt</th>\n",
       "      <th>Credit_Utilization_Ratio</th>\n",
       "      <th>Credit_History_Age</th>\n",
       "      <th>Payment_of_Min_Amount</th>\n",
       "      <th>Total_EMI_per_month</th>\n",
       "      <th>Amount_invested_monthly</th>\n",
       "      <th>Payment_Behaviour</th>\n",
       "      <th>Monthly_Balance</th>\n",
       "      <th>Credit_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.170850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.944960</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>118.280222</td>\n",
       "      <td>3</td>\n",
       "      <td>284.629162</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>34.429817</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.170850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>28.609352</td>\n",
       "      <td>267</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>81.699521</td>\n",
       "      <td>4</td>\n",
       "      <td>331.209863</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.170850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>31.377862</td>\n",
       "      <td>268</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>199.458074</td>\n",
       "      <td>5</td>\n",
       "      <td>223.451310</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>1824.843333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>24.797347</td>\n",
       "      <td>269</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>41.420153</td>\n",
       "      <td>1</td>\n",
       "      <td>341.489231</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>19114.12</td>\n",
       "      <td>4194.170850</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>809.98</td>\n",
       "      <td>27.262259</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>49.574949</td>\n",
       "      <td>62.430172</td>\n",
       "      <td>6</td>\n",
       "      <td>340.479212</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79800</th>\n",
       "      <td>1</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>20002.88</td>\n",
       "      <td>1929.906667</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4913</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3571.70</td>\n",
       "      <td>37.140784</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>60.964772</td>\n",
       "      <td>34.662906</td>\n",
       "      <td>0</td>\n",
       "      <td>337.362988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79801</th>\n",
       "      <td>2</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>39628.99</td>\n",
       "      <td>3359.415833</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>683</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>502.38</td>\n",
       "      <td>29.135447</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>58638.000000</td>\n",
       "      <td>180.733095</td>\n",
       "      <td>4</td>\n",
       "      <td>400.104466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79802</th>\n",
       "      <td>5</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>39628.99</td>\n",
       "      <td>3359.415833</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.546679</td>\n",
       "      <td>2.0</td>\n",
       "      <td>683</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>502.38</td>\n",
       "      <td>41.255522</td>\n",
       "      <td>380</td>\n",
       "      <td>1</td>\n",
       "      <td>35.104023</td>\n",
       "      <td>24.028477</td>\n",
       "      <td>0</td>\n",
       "      <td>516.809083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79803</th>\n",
       "      <td>4</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>39628.99</td>\n",
       "      <td>3359.415833</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>683</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>502.38</td>\n",
       "      <td>33.638208</td>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "      <td>35.104023</td>\n",
       "      <td>251.672582</td>\n",
       "      <td>3</td>\n",
       "      <td>319.164979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79804</th>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>39628.99</td>\n",
       "      <td>3359.415833</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>683</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>502.38</td>\n",
       "      <td>34.192463</td>\n",
       "      <td>382</td>\n",
       "      <td>1</td>\n",
       "      <td>35.104023</td>\n",
       "      <td>167.163865</td>\n",
       "      <td>6</td>\n",
       "      <td>393.673696</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79805 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Month        Age  Occupation  Annual_Income  Monthly_Inhand_Salary  \\\n",
       "0          2  23.000000          13       19114.12            4194.170850   \n",
       "1          6  34.429817          13       19114.12            4194.170850   \n",
       "2          0  23.000000          13       19114.12            4194.170850   \n",
       "3          7  23.000000          13       19114.12            1824.843333   \n",
       "4          5  23.000000          13       19114.12            4194.170850   \n",
       "...      ...        ...         ...            ...                    ...   \n",
       "79800      1  29.000000           1       20002.88            1929.906667   \n",
       "79801      2  25.000000           9       39628.99            3359.415833   \n",
       "79802      5  25.000000           9       39628.99            3359.415833   \n",
       "79803      4  25.000000           9       39628.99            3359.415833   \n",
       "79804      1  25.000000           9       39628.99            3359.415833   \n",
       "\n",
       "       Num_Bank_Accounts  Num_Credit_Card  Interest_Rate  Num_of_Loan  \\\n",
       "0                    3.0              4.0       3.000000          4.0   \n",
       "1                    3.0              4.0       3.000000          4.0   \n",
       "2                    3.0              4.0       3.000000          4.0   \n",
       "3                    3.0              4.0       3.000000          4.0   \n",
       "4                    3.0              4.0       3.000000          4.0   \n",
       "...                  ...              ...            ...          ...   \n",
       "79800               10.0              8.0      29.000000          5.0   \n",
       "79801                4.0              6.0       7.000000          2.0   \n",
       "79802                4.0              6.0      14.546679          2.0   \n",
       "79803                4.0              6.0       7.000000          2.0   \n",
       "79804                4.0              6.0       7.000000          2.0   \n",
       "\n",
       "       Type_of_Loan  ...  Credit_Mix  Outstanding_Debt  \\\n",
       "0               128  ...           1            809.98   \n",
       "1               128  ...           1            809.98   \n",
       "2               128  ...           1            809.98   \n",
       "3               128  ...           1            809.98   \n",
       "4               128  ...           1            809.98   \n",
       "...             ...  ...         ...               ...   \n",
       "79800          4913  ...           0           3571.70   \n",
       "79801           683  ...           1            502.38   \n",
       "79802           683  ...           1            502.38   \n",
       "79803           683  ...           1            502.38   \n",
       "79804           683  ...           1            502.38   \n",
       "\n",
       "       Credit_Utilization_Ratio  Credit_History_Age  Payment_of_Min_Amount  \\\n",
       "0                     31.944960                   0                      1   \n",
       "1                     28.609352                 267                      1   \n",
       "2                     31.377862                 268                      1   \n",
       "3                     24.797347                 269                      1   \n",
       "4                     27.262259                 270                      1   \n",
       "...                         ...                 ...                    ...   \n",
       "79800                 37.140784                  75                      2   \n",
       "79801                 29.135447                 376                      1   \n",
       "79802                 41.255522                 380                      1   \n",
       "79803                 33.638208                 381                      1   \n",
       "79804                 34.192463                 382                      1   \n",
       "\n",
       "       Total_EMI_per_month  Amount_invested_monthly  Payment_Behaviour  \\\n",
       "0                49.574949               118.280222                  3   \n",
       "1                49.574949                81.699521                  4   \n",
       "2                49.574949               199.458074                  5   \n",
       "3                49.574949                41.420153                  1   \n",
       "4                49.574949                62.430172                  6   \n",
       "...                    ...                      ...                ...   \n",
       "79800            60.964772                34.662906                  0   \n",
       "79801         58638.000000               180.733095                  4   \n",
       "79802            35.104023                24.028477                  0   \n",
       "79803            35.104023               251.672582                  3   \n",
       "79804            35.104023               167.163865                  6   \n",
       "\n",
       "       Monthly_Balance  Credit_Score  \n",
       "0           284.629162             2  \n",
       "1           331.209863             2  \n",
       "2           223.451310             2  \n",
       "3           341.489231             2  \n",
       "4           340.479212             2  \n",
       "...                ...           ...  \n",
       "79800       337.362988             1  \n",
       "79801       400.104466             1  \n",
       "79802       516.809083             0  \n",
       "79803       319.164979             1  \n",
       "79804       393.673696             0  \n",
       "\n",
       "[79805 rows x 24 columns]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eliminamos la primera columan que seria nuestro \"id\" ya que no nos sirve para el analisis, que esa columna es unnamed\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "#ahora tenemos un dataframe\n",
    "#Imprimimos en una tabla el dataset para hacer un analisis mas claro.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis del dataset\n",
    "Hacemos un analisis del dataset mostrando su informacion usando la funcion de `info()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34000 entries, 0 to 33999\n",
      "Data columns (total 20 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Feature_1   34000 non-null  float64\n",
      " 1   Feature_2   34000 non-null  float64\n",
      " 2   Feature_3   34000 non-null  float64\n",
      " 3   Feature_4   34000 non-null  float64\n",
      " 4   Feature_5   34000 non-null  float64\n",
      " 5   Feature_6   34000 non-null  float64\n",
      " 6   Feature_7   34000 non-null  float64\n",
      " 7   Feature_8   34000 non-null  float64\n",
      " 8   Feature_9   34000 non-null  float64\n",
      " 9   Feature_10  34000 non-null  float64\n",
      " 10  Feature_11  34000 non-null  float64\n",
      " 11  Feature_12  34000 non-null  float64\n",
      " 12  Feature_13  34000 non-null  float64\n",
      " 13  Feature_14  34000 non-null  float64\n",
      " 14  Feature_15  34000 non-null  float64\n",
      " 15  Feature_16  34000 non-null  float64\n",
      " 16  Feature_17  34000 non-null  float64\n",
      " 17  Feature_18  34000 non-null  float64\n",
      " 18  Feature_19  34000 non-null  float64\n",
      " 19  Class       34000 non-null  float64\n",
      "dtypes: float64(20)\n",
      "memory usage: 5.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mostrando la tabla nos damos cuenta que nuestra Y a predicir es el **Class**, para tener una mejor vision de la cantidad de clases que existe, se hizo el siguiente codigo:\n",
    "\n",
    "donde separamos nuestra columna Y con `value_counts()` este método de pandas cuenta el número de veces que aparece cada valor único en la columna **Class** del DataFrame. Devuelve una Serie pandas donde los índices son los valores únicos de la columna **Class** y los valores son el recuento de ocurrencias de cada valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la cantidad de caracteristicas es: 19\n",
      "la cantidad de clases es: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Class\n",
       "4.0    6881\n",
       "1.0    6808\n",
       "2.0    6803\n",
       "3.0    6770\n",
       "0.0    6738\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#para contar cuantas clases contiene nuestra columna y\n",
    "class_counts = df[\"Class\"].value_counts()\n",
    "\n",
    "#para contar cuantas caracteristicas tiene nuestro dataset, obviamente con sin contar nuestra y, por eso lo dropeamos, tambien dropeamos la primera columna que no tiene nombre\n",
    "feactures_counts =df.drop(['Class'], axis=1)\n",
    "feactures_counts = feactures_counts.shape[1]\n",
    "\n",
    "print(f\"la cantidad de caracteristicas es: { feactures_counts}\")\n",
    "print(f'la cantidad de clases es: 5')\n",
    "\n",
    "#mostramos la cantidad de clases tiene, y en que cantidad\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#almacenamos la cantidad de caracteristicas en una variable\n",
    "input_layer_size  = feactures_counts;\n",
    "\n",
    "#almacenamos la cantidad de clases en una variable\n",
    "\n",
    "#para este caso no es necesario cambiar los valores de la ultima clase, ya que este cuenta con 0,1,2, \n",
    "# en caso de contener 1,2,3 se tendria que hacer los cambios necesarios para que sea 1,2,0, o simplememte suma 1 a la cantidad de clases.\n",
    "num_labels = 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separacion del 80% de los datos para entrenamiento y 20% para pruebas\n",
    "\n",
    "Se debe tomar en cuenta que cada clase tiene su propia cantidad, por lo cual separarlos directamente en un 80% para entrenamiento y un 20% para test no seria tan efectivo, ya que puede que en el 80% hay mas datos de una clase que las otras, provocando que nuestro modelo no conozca mucho sobre esa clase, por lo cual debe separarse un 80% para entrenamiento y un 20% para pruebas de cada clase.\n",
    "\n",
    "Para este hacemos uso de la libreria **train_test_split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos uso del DataFrame llamado 'df' que contiene nuestros datos datos\n",
    "# y es la columna que contiene las etiquetas de clase (en este caso, 'Credit_Score')\n",
    "\n",
    "#creamos una variable temporal que contentra toda la columna de 'Credit_Score'\n",
    "y_temp = df['Class']\n",
    "\n",
    "# Para la clase 0\n",
    "\n",
    "#donde y_temp es igual a 0, separamos los datos en train_class_0, test_class_0\n",
    "data_class_0 = df[y_temp == 0]\n",
    "train_class_0, test_class_0 = train_test_split(data_class_0, test_size=0.2, random_state=42)\n",
    "\n",
    "# Para la clase 1\n",
    "\n",
    "#donde y_temp es igual a 1, separamos los datos en train_class_1, test_class_1\n",
    "data_class_1 = df[y_temp == 1]\n",
    "train_class_1, test_class_1 = train_test_split(data_class_1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Para la clase 2\n",
    "\n",
    "#donde y_temp es igual a 2, separamos los datos en train_class_2, test_class_2\n",
    "data_class_2 = df[y_temp == 2]\n",
    "train_class_2, test_class_2 = train_test_split(data_class_2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Para la clase 3\n",
    "\n",
    "#donde y_temp es igual a 3, separamos los datos en train_class_3, test_class_3\n",
    "data_class_3 = df[y_temp == 3]\n",
    "train_class_3, test_class_3 = train_test_split(data_class_3, test_size=0.2, random_state=42)\n",
    "\n",
    "# Para la clase 4\n",
    "\n",
    "#donde y_temp es igual a 4, separamos los datos en train_class_4, test_class_4\n",
    "data_class_4 = df[y_temp == 4]\n",
    "train_class_4, test_class_4 = train_test_split(data_class_4, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "haciendo conteo de separacion de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para la clase 0 tenemos una cantidad de: 6738 donde el 80% es: 5390 y el 20% es: 1348\n",
      "Para la clase 1 tenemos una cantidad de: 6808 donde el 80% es: 5446 y el 20% es: 1362\n",
      "Para la clase 2 tenemos una cantidad de: 6803 donde el 80% es: 5442 y el 20% es: 1361\n",
      "Para la clase 3 tenemos una cantidad de: 6770 donde el 80% es: 5416 y el 20% es: 1354\n",
      "Para la clase 4 tenemos una cantidad de: 6881 donde el 80% es: 5504 y el 20% es: 1377\n",
      "La cantidad total de datos es: 34000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Para la clase 0 tenemos una cantidad de: { data_class_0.shape[0]} donde el 80% es: {train_class_0.shape[0]} y el 20% es: {test_class_0.shape[0]}\")\n",
    "print(f\"Para la clase 1 tenemos una cantidad de: { data_class_1.shape[0]} donde el 80% es: {train_class_1.shape[0]} y el 20% es: {test_class_1.shape[0]}\")\n",
    "print(f\"Para la clase 2 tenemos una cantidad de: { data_class_2.shape[0]} donde el 80% es: {train_class_2.shape[0]} y el 20% es: {test_class_2.shape[0]}\")\n",
    "print(f\"Para la clase 3 tenemos una cantidad de: { data_class_3.shape[0]} donde el 80% es: {train_class_3.shape[0]} y el 20% es: {test_class_3.shape[0]}\")\n",
    "print(f\"Para la clase 4 tenemos una cantidad de: { data_class_4.shape[0]} donde el 80% es: {train_class_4.shape[0]} y el 20% es: {test_class_4.shape[0]}\")\n",
    "print(f\"La cantidad total de datos es: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos cada uno en sus X_train, y_train, X_test y y_test respectivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para la parte de entrenamiento, separamos las caracteristicas de la etiqueta\n",
    "\n",
    "#para la clase 0\n",
    "X_train_class_0 = train_class_0.drop(['Class'], axis=1)\n",
    "y_train_class_0 = train_class_0['Class']\n",
    "\n",
    "#para la clase 1\n",
    "X_train_class_1 = train_class_1.drop(['Class'], axis=1)\n",
    "y_train_class_1 = train_class_1['Class']\n",
    "\n",
    "#para la clase 2\n",
    "X_train_class_2 = train_class_2.drop(['Class'], axis=1)\n",
    "y_train_class_2 = train_class_2['Class']\n",
    "\n",
    "#para la clase 3\n",
    "X_train_class_3 = train_class_3.drop(['Class'], axis=1)\n",
    "y_train_class_3 = train_class_3['Class']\n",
    "\n",
    "#para la clase 4\n",
    "X_train_class_4 = train_class_4.drop(['Class'], axis=1)\n",
    "y_train_class_4 = train_class_4['Class']\n",
    "\n",
    "#ahora para la parte de pruebas, separamos las caracteristicas de la etiqueta\n",
    "#para la clase 0\n",
    "X_test_class_0 = test_class_0.drop(['Class'], axis=1)\n",
    "y_test_class_0 = test_class_0['Class']\n",
    "\n",
    "#para la clase 1\n",
    "X_test_class_1 = test_class_1.drop(['Class'], axis=1)\n",
    "y_test_class_1 = test_class_1['Class']\n",
    "\n",
    "#para la clase 2\n",
    "X_test_class_2 = test_class_2.drop(['Class'], axis=1)\n",
    "y_test_class_2 = test_class_2['Class']\n",
    "\n",
    "#para la clase 3\n",
    "X_test_class_3 = test_class_3.drop(['Class'], axis=1)\n",
    "y_test_class_3 = test_class_3['Class']\n",
    "\n",
    "#para la clase 4\n",
    "X_test_class_4 = test_class_4.drop(['Class'], axis=1)\n",
    "y_test_class_4 = test_class_4['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora unimos todos en una sola matriz para X y y:\n",
    "pero luego debemos mezclar los datos, haciendo uso de ``np.random.permutation(len(X))`` genera un arreglo de índices permutados aleatoriamente.\n",
    "Luego, estos índices se usan para reorganizar tanto las características como las etiquetas de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando los datos de entrenamiento y pruebas\n",
    "\n",
    "#para los datos de entrenamiento\n",
    "X_train = pd.concat([X_train_class_0, X_train_class_1, X_train_class_2]).values\n",
    "y_train = pd.concat([y_train_class_0, y_train_class_1, y_train_class_2]).values\n",
    "\n",
    "\n",
    "indices_train = np.random.permutation(len(X_train))\n",
    "X_train = X_train[indices_train]\n",
    "y_train = y_train[indices_train]\n",
    "m_train = len(y_train)\n",
    "\n",
    "#para los datos de pruebas\n",
    "X_test = pd.concat([X_test_class_0, X_test_class_1, X_test_class_2]).values\n",
    "y_test = pd.concat([y_test_class_0, y_test_class_1, y_test_class_2]).values\n",
    "\n",
    "indices_test = np.random.permutation(len(X_test))\n",
    "X_test = X_test[indices_test]\n",
    "y_test = y_test[indices_test]\n",
    "m_test = len(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos algunos datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X[:,0]   X[:, 1]   X[:, 2]   X[:, 3]   X[:, 4]   X[:, 5]   X[:, 6]   X[:, 7]   X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11]  X[:, 12]  X[:, 13]  X[:, 14]  X[:, 15]  X[:, 16]  X[:, 17]X[:, 18]\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "         1         1         4         6         2         4       2        81        93        56       121        45        51        33       129        23        79        86      77\n",
      "         1         0         0         0         0         0       9        31       115        33        51        43        31        50       129        76       111       122     131\n",
      "         0         1         5         7         9         2       7        26       150        88       102        82        55        72        88       101        97        54      61\n",
      "         1         1         1         9         8         9       7       107       128        62       138        90       127       135        83        72       142        53     120\n",
      "         0         0         2         0         3         5       8       104       132       128       122       125        61       100        54       136       101        88      55\n",
      "         1         1        10         9         1         1       6        69       133       122        46       113       147        41        54       143        68        79      88\n",
      "         1         1         0         4         4         1       6        47       115       121       111        26        67       140       136       119       123        44     119\n",
      "         1         1         8         7         7         2       6        79       112       149       147        44        33       133        29        50        91       106      31\n",
      "         1         0         7         9         8         5       6        64        47       123        91        42       104        65        72       120        42        77      56\n",
      "         0         0         3         4         3         5       6        89        43       149       102        63        43        25        97       110        22       112      62\n",
      " \n",
      "El 80% de ejemplos para entrenamiento son la cantidad de: 16278 de ejemplos\n",
      "El 20% de ejemplos para pruebas son la cantidad de: 4071 de ejemplos\n",
      "La cantidad total de ejemplos es de: 34000 de ejemplos\n"
     ]
    }
   ],
   "source": [
    "#Visualizamos una cantidad de datos de entrenamiento\n",
    "print('{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>6s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'X[:, 11]', 'X[:, 12]', \n",
    "    'X[:, 13]', 'X[:, 14]', 'X[:, 15]', 'X[:, 16]', 'X[:, 17]', 'X[:, 18]','Y'\n",
    "))\n",
    "print('-' * 250)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:8.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:8.0f}'.format(\n",
    "        X_train[i, 0],\n",
    "        X_train[i, 1],\n",
    "        X_train[i, 2], \n",
    "        X_train[i, 3], \n",
    "        X_train[i, 4], \n",
    "        X_train[i, 5], \n",
    "        X_train[i, 6], \n",
    "        X_train[i, 7], \n",
    "        X_train[i, 8], \n",
    "        X_train[i, 9], \n",
    "        X_train[i, 10],\n",
    "        X_train[i, 11],\n",
    "        X_train[i, 12], \n",
    "        X_train[i, 13], \n",
    "        X_train[i, 14], \n",
    "        X_train[i, 15], \n",
    "        X_train[i, 16],\n",
    "        X_train[i, 17],\n",
    "        X_train[i, 18],\n",
    "        y_train[i]\n",
    "    ))\n",
    "\n",
    "print(\" \")\n",
    "print('El 80% de ejemplos para entrenamiento son la cantidad de: {:.0f} de ejemplos'.format( len(X_train)))\n",
    "print('El 20% de ejemplos para pruebas son la cantidad de: {:.0f} de ejemplos'.format( len(X_test)))\n",
    "print('La cantidad total de ejemplos es de: {:.0f} de ejemplos'.format( len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion para la Normalización de caracteristicas\n",
    "\n",
    "Al visualizar los datos se puede observar que las caracteristicas tienen diferentes magnitudes, por lo cual se debe transformar cada valor en una escala de valores similares, esto con el fin de que el descenso por el gradiente pueda converger mas rapidamente. En este caso\n",
    "\n",
    "Hacemos el uso de la siguiente funcion para normalizar los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  featureNormalize(X):\n",
    "    X_norm = X.copy()\n",
    "\n",
    "    #creamos un array de ceros con una longitud igual al número de columnas en el array X. La variable mu y sigma se inicializa como este array de ceros.\n",
    "    mu = np.zeros(X.shape[1])\n",
    "    sigma = np.zeros(X.shape[1])\n",
    "\n",
    "    #Creamos el promedio de cada filaa de X\n",
    "    #media de cada columna\n",
    "    mu = np.mean(X, axis = 0)\n",
    "    \n",
    "    #desviacion estandar de cada fila de X\n",
    "    sigma = np.std(X, axis = 0)\n",
    "    \n",
    "    sigma[sigma == 0] = 1\n",
    "    \n",
    "    #normalizamos los datos con la siguiente formula\n",
    "    X_norm = (X - mu) / sigma\n",
    "\n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion para el calculo de la sigmoide\n",
    "\n",
    "También conocida como la función logística, es una función matemática que toma cualquier número real como entrada y devuelve un valor en el rango de 0 a 1. Donde nuestra **Z** es nuestra hipotesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    z = np.array(z)\n",
    "\n",
    "    g = np.zeros(z.shape)\n",
    "\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion de calculo de costo con regularizacion\n",
    "\n",
    "Aplicando la teoria donde nuestra funcion recibira parametros como Theta, x, y y lamda_, donde lamda_ es nuestro parametro de regularizacion.\n",
    "\n",
    "Donde la funcion nos devuelve un costo y nuestro gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrCostFunctionCR(theta, X, y, lambda_):\n",
    "    #creamos una variable m que contiene la longitud de y\n",
    "    m = y.size\n",
    "\n",
    "    # convierte las etiquetas a valores enteros si son boleanos\n",
    "    if y.dtype == bool:\n",
    "        y = y.astype(int)\n",
    "\n",
    "    #inicializamos J y grad\n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "\n",
    "    #calculamos h haciendo uso de la funcion sigmoid, donde h es nuestra hipotesis\n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "\n",
    "    temp = theta\n",
    "    temp[0] = 0\n",
    "\n",
    "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n",
    "\n",
    "    grad = (1 / m) * (h - y).dot(X)\n",
    "    \n",
    "    grad = grad + (lambda_ / m) * temp\n",
    "\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion de One-vs-all con regularizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneVsAllCR(X, y, num_labels, lambda_):\n",
    "    # algunas variables utiles\n",
    "    #m es la longitud de y, n es la cantidad de columnas en X\n",
    "    m, n = X.shape\n",
    "\n",
    "    # inicializamos la matriz de thetas con ceros, y con n+1 columnas que seria nuestro sesgo\n",
    "    all_theta = np.zeros((num_labels, n + 1))\n",
    "\n",
    "    # Agrega unos a la matriz X\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "\n",
    "    # iteramos sobre cada etiqueta (clase) y entrenamos un clasificador\n",
    "    for c in np.arange(num_labels):\n",
    "        initial_theta = np.zeros(n + 1)\n",
    "        options = {'maxiter': 20000}\n",
    "        res = optimize.minimize(lrCostFunctionCR,\n",
    "                                initial_theta,\n",
    "                                (X, (y == c), lambda_),\n",
    "                                jac=True,\n",
    "                                method='CG',\n",
    "                                options=options)\n",
    "\n",
    "        all_theta[c] = res.x\n",
    "\n",
    "    return all_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion de calculo de costo sin regularizacio\n",
    "\n",
    "Para este caso solo quitamos la sumatoria `+ (lambda_ / (2 * m)) * np.sum(np.square(temp))` a la ecuacion de costo, donde esto se aplicado sin regularizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrCostFunctionSR(theta, X, y):\n",
    "    #creamos una variable m que contiene la longitud de y\n",
    "    m = y.size\n",
    "\n",
    "    # convierte las etiquetas a valores enteros si son boleanos\n",
    "    if y.dtype == bool:\n",
    "        y = y.astype(int)\n",
    "\n",
    "    #inicializamos J y grad\n",
    "    J = 0\n",
    "    \n",
    "    # grad = np.zeros(theta.shape)\n",
    "\n",
    "    #calculamos h haciendo uso de la funcion sigmoid, donde h es nuestra hipotesis\n",
    "    h = sigmoid(X.dot(theta.T))\n",
    "\n",
    "    # temp = theta\n",
    "    # temp[0] = 0\n",
    "\n",
    "    # J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n",
    "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n",
    "\n",
    "    grad = (1 / m) * (h - y).dot(X)\n",
    "    \n",
    "    # grad = grad + (lambda_ / m) * temp\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion de One-vs-all sin regularizacion\n",
    "\n",
    "Como esta funcion sera sin regularizar, ya no se necesita usar el parametro `lambda_` por lo tanto al momento de obtener las thetas para cada clase ya no es necesario enviarle un parametro `lambda_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneVsAllSR(X, y, num_labels):\n",
    "    # algunas variables utiles\n",
    "    #m es la longitud de y, n es la cantidad de columnas en X\n",
    "    m, n = X.shape\n",
    "\n",
    "    # inicializamos la matriz de thetas con ceros, y con n+1 columnas que seria nuestro sesgo\n",
    "    all_theta = np.zeros((num_labels, n + 1))\n",
    "\n",
    "    # Agrega unos a la matriz X\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "\n",
    "    # iteramos sobre cada etiqueta (clase) y entrenamos un clasificador\n",
    "    for c in np.arange(num_labels):\n",
    "        initial_theta = np.zeros(n + 1)\n",
    "        options = {'maxiter': 20000}\n",
    "        res = optimize.minimize(lrCostFunctionSR,\n",
    "                                initial_theta,\n",
    "                                (X, (y == c)),\n",
    "                                jac=True,\n",
    "                                method='CG',\n",
    "                                options=options)\n",
    "\n",
    "        all_theta[c] = res.x\n",
    "\n",
    "    return all_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion para Prediccion One-vs-all\n",
    "Aqui creamos solo la funcion, donde mandamos los parametros de `all_theta` y la `X` que en este caso puede ser las X de prueba, pero antes deben de estar normalizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictOneVsAll(all_theta, X):\n",
    "    m = X.shape[0];\n",
    "    num_labels = all_theta.shape[0]\n",
    "\n",
    "    # inicializamos la matriz de p con ceros\n",
    "    p = np.zeros(m)\n",
    "\n",
    "    # añadimos unos a la matriz de X\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "    p = np.argmax(sigmoid(X.dot(all_theta.T)), axis = 1)\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Usando regularizacion\n",
    "\n",
    "La regularización es una técnica utilizada en el aprendizaje automático para prevenir el **sobreajuste (overfitting)** de un modelo a los datos de entrenamiento.\n",
    "\n",
    "El sobreajuste ocurre cuando un modelo se ajusta demasiado bien a los datos de entrenamiento y captura el ruido o las fluctuaciones aleatorias en los datos en lugar de aprender la verdadera relación subyacente entre las características y la variable objetivo. Esto puede resultar en un rendimiento deficiente del modelo cuando se enfrenta a nuevos datos que no formaban parte del conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Clasificacion Multiclase\n",
    "\n",
    "Carga de los datos para la clasificacion multiclase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X[:,0]   X[:, 1]   X[:, 2]   X[:, 3]   X[:, 4]   X[:, 5]   X[:, 6]   X[:, 7]   X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11]  X[:, 12]  X[:, 13]  X[:, 14]  X[:, 15]  X[:, 16]  X[:, 17]  X[:, 18]     Y\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "         1         1         4         6         2         4       2        81        93        56       121        45        51        33       129        23        79        86        77       0\n",
      "         1         0         0         0         0         0       9        31       115        33        51        43        31        50       129        76       111       122       131       1\n",
      "         0         1         5         7         9         2       7        26       150        88       102        82        55        72        88       101        97        54        61       0\n",
      "         1         1         1         9         8         9       7       107       128        62       138        90       127       135        83        72       142        53       120       1\n",
      "         0         0         2         0         3         5       8       104       132       128       122       125        61       100        54       136       101        88        55       1\n",
      "         1         1        10         9         1         1       6        69       133       122        46       113       147        41        54       143        68        79        88       2\n",
      "         1         1         0         4         4         1       6        47       115       121       111        26        67       140       136       119       123        44       119       0\n",
      "         1         1         8         7         7         2       6        79       112       149       147        44        33       133        29        50        91       106        31       1\n",
      "         1         0         7         9         8         5       6        64        47       123        91        42       104        65        72       120        42        77        56       2\n",
      "         0         0         3         4         3         5       6        89        43       149       102        63        43        25        97       110        22       112        62       1\n",
      " \n",
      "El 80% de ejemplos para entrenamiento son la cantidad de: 16278 de ejemplos\n",
      "El 20% de ejemplos para pruebas son la cantidad de: 4071 de ejemplos\n",
      "La cantidad total de ejemplos es de: 34000 de ejemplos\n"
     ]
    }
   ],
   "source": [
    "#estos datos seran usados para el entrenamiento\n",
    "X_testCR = X_test.copy()\n",
    "y_testCR = y_test.copy()\n",
    "m_test_CR = len(y_testCR)\n",
    "\n",
    "#estos datos seran usados para el test\n",
    "X_trainCR = X_train.copy()\n",
    "y_trainCR = y_train.copy()\n",
    "m_train_CR = len(y_trainCR)\n",
    "\n",
    "#Visualizamos una cantidad de datos de entrenamiento\n",
    "print('{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>6s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'X[:, 11]', 'X[:, 12]', \n",
    "    'X[:, 13]', 'X[:, 14]', 'X[:, 15]', 'X[:, 16]', 'X[:, 17]', 'X[:, 18]' ,'Y'\n",
    "))\n",
    "print('-' * 250)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:8.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:8.0f}'.format(\n",
    "        X_trainCR[i, 0],\n",
    "        X_trainCR[i, 1],\n",
    "        X_trainCR[i, 2], \n",
    "        X_trainCR[i, 3], \n",
    "        X_trainCR[i, 4], \n",
    "        X_trainCR[i, 5], \n",
    "        X_trainCR[i, 6], \n",
    "        X_trainCR[i, 7], \n",
    "        X_trainCR[i, 8], \n",
    "        X_trainCR[i, 9], \n",
    "        X_trainCR[i, 10],\n",
    "        X_trainCR[i, 11],\n",
    "        X_trainCR[i, 12], \n",
    "        X_trainCR[i, 13], \n",
    "        X_trainCR[i, 14], \n",
    "        X_trainCR[i, 15], \n",
    "        X_trainCR[i, 16],\n",
    "        X_trainCR[i, 17],\n",
    "        X_trainCR[i, 18], \n",
    "        y_trainCR[i]\n",
    "    ))\n",
    "\n",
    "print(\" \")\n",
    "print('El 80% de ejemplos para entrenamiento son la cantidad de: {:.0f} de ejemplos'.format( len(X_train)))\n",
    "print('El 20% de ejemplos para pruebas son la cantidad de: {:.0f} de ejemplos'.format( len(X_test)))\n",
    "print('La cantidad total de ejemplos es de: {:.0f} de ejemplos'.format( len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Normalizacion de las caracteristicas\n",
    "\n",
    "Se hace uso de la funcion de `featureNormalize(X) ` donde se recibe un parametro de tipo matriz para normalizar cada dato dentro de ella, retornandome la **matriz normalizda**, **sigma(desviacion estandar)**, y mi **mu(media)**.\n",
    "\n",
    "Almacenando los datos normalizados en **X_norm** usando la funcion **featureNormaliza()**, normalizando los datos de X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X[:,0]   X[:, 1]   X[:, 2]   X[:, 3]   X[:, 4]   X[:, 5]   X[:, 6]   X[:, 7]   X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11]  X[:, 12]  X[:, 13]  X[:, 14]  X[:, 15]  X[:, 16]  X[:, 17]  X[:, 18]       Y\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "      1.02      0.45     -0.28      0.20     -1.15     -0.31     -0.93     -0.11      0.22     -0.77      0.98     -1.06     -0.91     -1.40      1.16     -1.66     -0.17      0.01     -0.21       0\n",
      "      0.10     -0.59     -1.65     -1.70     -1.69     -1.67      1.44     -1.42      0.82     -1.37     -0.90     -1.11     -1.44     -0.93      1.16     -0.24      0.70      0.98      1.22       1\n",
      "     -1.59      0.79      0.03      0.75      1.24     -1.05      0.63     -1.57      1.73      0.10      0.46     -0.07     -0.82     -0.34      0.07      0.45      0.31     -0.83     -0.65       0\n",
      "      0.97      1.53     -1.29      1.32      1.15      1.50      0.81      0.59      1.14     -0.61      1.42      0.14      1.10      1.34     -0.05     -0.34      1.51     -0.86      0.91       1\n",
      "     -0.78     -1.18     -0.98     -1.62     -0.64     -0.16      0.93      0.51      1.24      1.16      1.00      1.07     -0.64      0.40     -0.83      1.38      0.42      0.08     -0.79       1\n",
      "      1.47      0.97      1.70      1.29     -1.24     -1.30      0.19     -0.43      1.29      1.00     -1.03      0.75      1.64     -1.18     -0.84      1.56     -0.46     -0.17      0.08       2\n",
      "      1.07      0.43     -1.56     -0.33     -0.26     -1.25      0.41     -1.00      0.81      0.98      0.71     -1.55     -0.48      1.46      1.36      0.92      1.00     -1.09      0.90       0\n",
      "      0.70      0.52      1.22      0.60      0.86     -1.11      0.21     -0.14      0.72      1.73      1.67     -1.09     -1.39      1.29     -1.49     -0.93      0.15      0.57     -1.43       1\n",
      "      0.83     -0.47      0.69      1.40      0.89     -0.04      0.41     -0.56     -1.01      1.04      0.16     -1.14      0.48     -0.53     -0.34      0.93     -1.15     -0.22     -0.78       2\n",
      "     -1.02     -0.34     -0.82     -0.26     -0.79      0.03      0.18      0.11     -1.12      1.72      0.47     -0.56     -1.13     -1.60      0.32      0.68     -1.68      0.72     -0.63       1\n"
     ]
    }
   ],
   "source": [
    "X_norm_CR, mu_CR, sigma_CR = featureNormalize(X_trainCR)\n",
    "\n",
    "# imprimir todos las X_norm de datos solo 10\n",
    "print('{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>8s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'X[:, 11]', 'X[:, 12]', \n",
    "    'X[:, 13]', 'X[:, 14]', 'X[:, 15]', 'X[:, 16]', 'X[:, 17]', 'X[:, 18]', 'Y'\n",
    "))\n",
    "print('-' * 250)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:8.0f}'.format(\n",
    "        X_norm_CR[i, 0],\n",
    "        X_norm_CR[i, 1],\n",
    "        X_norm_CR[i, 2], \n",
    "        X_norm_CR[i, 3], \n",
    "        X_norm_CR[i, 4], \n",
    "        X_norm_CR[i, 5], \n",
    "        X_norm_CR[i, 6], \n",
    "        X_norm_CR[i, 7], \n",
    "        X_norm_CR[i, 8], \n",
    "        X_norm_CR[i, 9], \n",
    "        X_norm_CR[i, 10],\n",
    "        X_norm_CR[i, 11],\n",
    "        X_norm_CR[i, 12], \n",
    "        X_norm_CR[i, 13], \n",
    "        X_norm_CR[i, 14], \n",
    "        X_norm_CR[i, 15], \n",
    "        X_norm_CR[i, 16],\n",
    "        X_norm_CR[i, 17],\n",
    "        X_norm_CR[i, 18],\n",
    "        y_trainCR[i]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Clasificacion One-vs-All\n",
    "Aqui estariamos usando un ciclo for para iterar sobre cada una de las clases, luego haciendo uso de `optimize.minimize` que es un método de la biblioteca *scipy* que encuentra el mínimo de una función. En este caso, se trata de minimizar la función de costos de regresión logística `(lrCostFunction)`.\n",
    "\n",
    "Los parámetros iniciales ``(initial_theta)``.\n",
    "Una tupla que contiene los datos de entrenamiento ``(X)``, las etiquetas ``(y == c)``, y el parámetro de regularización ``(lambda_)``.\n",
    "``jac=True`` indica que la función de coste devuelve tanto el coste como el gradiente.\n",
    "El método de optimización ``('CG' significa Gradiente Conjugado).``\n",
    "El diccionario de opciones ``(options)``  que se establece en 1000 para limitar el número máximo de iteraciones del optimizador.\n",
    "\n",
    "\n",
    "Inicializamos nuestra lambda con valor de *0.005*, usamos la funcion de `oneVsAll` donde pasamos los parametros de *X_norm*, *num_labels* que seria la cantidad de clases que tenemos, y nuestro *lanbda* para asi obtener nuestros Thetas para cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 20)\n",
      "Thetha 0  para la clase 0: -0.7038115538616592  ;  Thetha 0  para la clase 1: -0.6879494051357162  ;  Thetha 0  para la clase 2: -0.6890724125948305  ;  Thetha 0  para la clase 3: -13.02493197071628  ;  Thetha 0  para la clase 4: -13.02493197071628\n",
      "Thetha 1  para la clase 0: 0.007576166821256505  ;  Thetha 1  para la clase 1: -0.013839309640579613  ;  Thetha 1  para la clase 2: 0.0063067139968171525  ;  Thetha 1  para la clase 3: 1.2385914891356424e-07  ;  Thetha 1  para la clase 4: 1.2385914891356424e-07\n",
      "Thetha 2  para la clase 0: -0.00589123448662068  ;  Thetha 2  para la clase 1: 0.008437120750493403  ;  Thetha 2  para la clase 2: -0.002576837841768889  ;  Thetha 2  para la clase 3: 1.2644276561375603e-07  ;  Thetha 2  para la clase 4: 1.2644276561375603e-07\n",
      "Thetha 3  para la clase 0: -0.009332020596166004  ;  Thetha 3  para la clase 1: -0.003206494221508328  ;  Thetha 3  para la clase 2: 0.01249536646954402  ;  Thetha 3  para la clase 3: -8.199021943464184e-09  ;  Thetha 3  para la clase 4: -8.199021943464184e-09\n",
      "Thetha 4  para la clase 0: 0.009683474157213424  ;  Thetha 4  para la clase 1: -0.009497677567737778  ;  Thetha 4  para la clase 2: -0.00014317543436269503  ;  Thetha 4  para la clase 3: 1.408525256900526e-07  ;  Thetha 4  para la clase 4: 1.408525256900526e-07\n",
      "Thetha 5  para la clase 0: 0.00978835398564908  ;  Thetha 5  para la clase 1: -0.014281796227702662  ;  Thetha 5  para la clase 2: 0.004540695025410774  ;  Thetha 5  para la clase 3: -1.6070213989572996e-07  ;  Thetha 5  para la clase 4: -1.6070213989572996e-07\n",
      "Thetha 6  para la clase 0: 0.008399413034872051  ;  Thetha 6  para la clase 1: -0.0030055996882079167  ;  Thetha 6  para la clase 2: -0.00536686128850922  ;  Thetha 6  para la clase 3: 1.7958389722966565e-08  ;  Thetha 6  para la clase 4: 1.7958389722966565e-08\n",
      "Thetha 7  para la clase 0: 0.022713189833911684  ;  Thetha 7  para la clase 1: 0.006943619271389007  ;  Thetha 7  para la clase 2: -0.029557863752571776  ;  Thetha 7  para la clase 3: 1.0819223813162901e-07  ;  Thetha 7  para la clase 4: 1.0819223813162901e-07\n",
      "Thetha 8  para la clase 0: -0.0061707967860762745  ;  Thetha 8  para la clase 1: 0.005042880156327374  ;  Thetha 8  para la clase 2: 0.0010971614213322119  ;  Thetha 8  para la clase 3: -1.585196373030161e-07  ;  Thetha 8  para la clase 4: -1.585196373030161e-07\n",
      "Thetha 9  para la clase 0: -0.02218049054261996  ;  Thetha 9  para la clase 1: 0.015500691515011721  ;  Thetha 9  para la clase 2: 0.006574304770332527  ;  Thetha 9  para la clase 3: -6.709869837875915e-08  ;  Thetha 9  para la clase 4: -6.709869837875915e-08\n",
      "Thetha 10  para la clase 0: -0.027856880248302608  ;  Thetha 10  para la clase 1: 0.018885324831244124  ;  Thetha 10  para la clase 2: 0.008836753207630896  ;  Thetha 10  para la clase 3: 3.6612425190663163e-07  ;  Thetha 10  para la clase 4: 3.6612425190663163e-07\n",
      "Thetha 11  para la clase 0: 0.009732222015873334  ;  Thetha 11  para la clase 1: 0.0037841718606097963  ;  Thetha 11  para la clase 2: -0.01347709104466588  ;  Thetha 11  para la clase 3: 2.3578904476096677e-07  ;  Thetha 11  para la clase 4: 2.3578904476096677e-07\n",
      "Thetha 12  para la clase 0: -0.020504028556502206  ;  Thetha 12  para la clase 1: 0.006355394286261217  ;  Thetha 12  para la clase 2: 0.014052369496876762  ;  Thetha 12  para la clase 3: 4.405674900142794e-08  ;  Thetha 12  para la clase 4: 4.405674900142794e-08\n",
      "Thetha 13  para la clase 0: -0.012528866131398588  ;  Thetha 13  para la clase 1: 0.0030391211741928356  ;  Thetha 13  para la clase 2: 0.009419573751059361  ;  Thetha 13  para la clase 3: 5.445518267392516e-08  ;  Thetha 13  para la clase 4: 5.445518267392516e-08\n",
      "Thetha 14  para la clase 0: 0.01178017279443138  ;  Thetha 14  para la clase 1: -0.00706190763690725  ;  Thetha 14  para la clase 2: -0.004660986555515358  ;  Thetha 14  para la clase 3: 4.843804375621267e-08  ;  Thetha 14  para la clase 4: 4.843804375621267e-08\n",
      "Thetha 15  para la clase 0: -0.005367752167795063  ;  Thetha 15  para la clase 1: -0.010035942784539684  ;  Thetha 15  para la clase 2: 0.015371756829296411  ;  Thetha 15  para la clase 3: 2.1493149326542375e-08  ;  Thetha 15  para la clase 4: 2.1493149326542375e-08\n",
      "Thetha 16  para la clase 0: -0.01733587243762115  ;  Thetha 16  para la clase 1: 0.012342492657829884  ;  Thetha 16  para la clase 2: 0.004910865072350337  ;  Thetha 16  para la clase 3: -5.1850065187582966e-08  ;  Thetha 16  para la clase 4: -5.1850065187582966e-08\n",
      "Thetha 17  para la clase 0: -0.0022737641009566724  ;  Thetha 17  para la clase 1: -0.003309197135159453  ;  Thetha 17  para la clase 2: 0.005585530081143354  ;  Thetha 17  para la clase 3: 7.03362643452712e-08  ;  Thetha 17  para la clase 4: 7.03362643452712e-08\n",
      "Thetha 18  para la clase 0: 0.02064525523168734  ;  Thetha 18  para la clase 1: -0.011301231115191991  ;  Thetha 18  para la clase 2: -0.009240246908475103  ;  Thetha 18  para la clase 3: 1.6765491807753342e-08  ;  Thetha 18  para la clase 4: 1.6765491807753342e-08\n",
      "Thetha 19  para la clase 0: -0.018925445257127867  ;  Thetha 19  para la clase 1: 0.015397929171359657  ;  Thetha 19  para la clase 2: 0.003429784321273283  ;  Thetha 19  para la clase 3: 1.3300743334086935e-07  ;  Thetha 19  para la clase 4: 1.3300743334086935e-07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lambda_ = 1000\n",
    "all_theta_CR = oneVsAllCR(X_norm_CR, y_trainCR, num_labels, lambda_)\n",
    "print(all_theta_CR.shape)\n",
    "\n",
    "#imprimimos todos los thetas para cada clase\n",
    "for i in range(all_theta_CR.shape[1]):\n",
    "    print(\"Thetha\",i,\" para la clase 0:\", all_theta_CR[0,i],\" ; \", \"Thetha\",i,\" para la clase 1:\", all_theta_CR[1,i],\" ; \", \"Thetha\",i,\" para la clase 2:\", all_theta_CR[2,i] , \" ; \", \"Thetha\",i,\" para la clase 3:\", all_theta_CR[3,i],\" ; \", \"Thetha\",i,\" para la clase 4:\", all_theta_CR[4,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Validaciones\n",
    "Para hacer las validaciones correspondientes se hizo el uso siguiendo el consejo de 80/20, donde 80% es para la fase de entrenamiento, y 20% es para la fase de prueba.\n",
    "\n",
    "Para este caso de validacion se hizo uso de la funcion de `predictOneVsAll()` creada anteriormente, los siguiente fue normalizar nuestra `X_test` que son el 20% para pruebas, ahora se procedio a normalizarlo haciendo uso de *mu* y *sigma* calculado anteriormente en la funcion de normalizacion.\n",
    "\n",
    "luego se hace uso de `np.mean` donde nos calcula el promedio de los valores booleanos en el array resultante de la comparación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Con los datos de entrenamiento\n",
    "Para este caso se uso los datos de `X_norm` usando la funcion de `predictOneVsAll()`, viendo el resultado de precision nos da un **34.83843%** el cual esta muy lejos de ser un buen modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del conjunto de entrenamiento: 34.83843%\n"
     ]
    }
   ],
   "source": [
    "# print(X_test.shape)\n",
    "pred_test_CR = predictOneVsAll(all_theta_CR, X_norm_CR)\n",
    "print('Precision del conjunto de entrenamiento: {:.5f}%'.format(np.mean(pred_test_CR == y_trainCR) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 con los datos de prueba\n",
    "Para este caso se uso los datos de `X_test`, luego se procedio a normalizar los datos. \n",
    "\n",
    "Usando la funcion de `predictOneVsAll()`, viendo el resultado de precision nos da un **34.36502%** , un poco en diferencia a la anterior prediccion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del conjunto de entrenamiento: 34.36502%\n"
     ]
    }
   ],
   "source": [
    "X_test1_CR = X_testCR.copy()\n",
    "# print(X_test.shape)\n",
    "X_test1_CR = (X_test1_CR - mu_CR) / sigma_CR\n",
    "pred_train_CR = predictOneVsAll(all_theta_CR, X_test1_CR)\n",
    "print('Precision del conjunto de entrenamiento: {:.5f}%'.format(np.mean(pred_train_CR == y_testCR) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se puede hacer las predicciones usando directamente la funcion `sigmoid()`, y luego imprimimos 30 predicciones para ver que tanto se asemejan con nuestra Y predicha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4071, 20)\n",
      "Prediccion: 0, Real: 0.0\n",
      "Prediccion: 2, Real: 0.0\n",
      "Prediccion: 1, Real: 0.0\n",
      "Prediccion: 0, Real: 2.0\n",
      "Prediccion: 0, Real: 0.0\n",
      "Prediccion: 0, Real: 2.0\n",
      "Prediccion: 0, Real: 0.0\n",
      "Prediccion: 2, Real: 0.0\n",
      "Prediccion: 1, Real: 0.0\n",
      "Prediccion: 0, Real: 1.0\n",
      "Prediccion: 2, Real: 1.0\n",
      "Prediccion: 0, Real: 2.0\n",
      "Prediccion: 0, Real: 2.0\n",
      "Prediccion: 0, Real: 0.0\n",
      "Prediccion: 2, Real: 1.0\n",
      "Prediccion: 1, Real: 1.0\n",
      "Prediccion: 1, Real: 0.0\n",
      "Prediccion: 0, Real: 1.0\n",
      "Prediccion: 1, Real: 1.0\n",
      "Prediccion: 1, Real: 1.0\n",
      "Prediccion: 1, Real: 1.0\n",
      "Prediccion: 0, Real: 2.0\n",
      "Prediccion: 1, Real: 0.0\n",
      "Prediccion: 0, Real: 1.0\n",
      "Prediccion: 1, Real: 2.0\n",
      "Prediccion: 1, Real: 0.0\n",
      "Prediccion: 0, Real: 0.0\n",
      "Prediccion: 1, Real: 0.0\n",
      "Prediccion: 2, Real: 1.0\n",
      "Prediccion: 2, Real: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#usando el mu y sigma calculado anteriormente, para realizar la normalizacion de los datos de prueba\n",
    "X_test1_CR = (X_testCR.copy() - mu_CR) / sigma_CR\n",
    "X_test1_CR = np.concatenate([np.ones((len(X_test1_CR), 1)), X_test1_CR], axis=1)\n",
    "\n",
    "print(X_test1_CR.shape)\n",
    "\n",
    "#para este ejemplo, vamos a mostrar las predicciones de las primeras 30 predicciones y compararlas con las reales\n",
    "p = np.argmax(sigmoid(X_test1_CR.dot(all_theta_CR.T)), axis = 1)\n",
    "\n",
    "for i in range(30):\n",
    "    print(f\"Prediccion: {p[i]}, Real: {y_test[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Usando sin regularizacion\n",
    "\n",
    "En esta parte del laboratorio no se usara la parte de regularizacion, esto para ver como es el comportamiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Clasificacion Multiclase\n",
    "\n",
    "Carga de los datos para la clasificacion multiclase sin usar regularizacion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X[:,0]   X[:, 1]   X[:, 2]   X[:, 3]   X[:, 4]   X[:, 5]   X[:, 6]   X[:, 7]   X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11]  X[:, 12]  X[:, 13]  X[:, 14]  X[:, 15]  X[:, 16]  X[:, 17]  X[:, 18]     Y\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "         1         1         4         6         2         4       2        81        93        56       121        45        51        33       129        23        79        86        77       0\n",
      "         1         0         0         0         0         0       9        31       115        33        51        43        31        50       129        76       111       122       131       1\n",
      "         0         1         5         7         9         2       7        26       150        88       102        82        55        72        88       101        97        54        61       0\n",
      "         1         1         1         9         8         9       7       107       128        62       138        90       127       135        83        72       142        53       120       1\n",
      "         0         0         2         0         3         5       8       104       132       128       122       125        61       100        54       136       101        88        55       1\n",
      "         1         1        10         9         1         1       6        69       133       122        46       113       147        41        54       143        68        79        88       2\n",
      "         1         1         0         4         4         1       6        47       115       121       111        26        67       140       136       119       123        44       119       0\n",
      "         1         1         8         7         7         2       6        79       112       149       147        44        33       133        29        50        91       106        31       1\n",
      "         1         0         7         9         8         5       6        64        47       123        91        42       104        65        72       120        42        77        56       2\n",
      "         0         0         3         4         3         5       6        89        43       149       102        63        43        25        97       110        22       112        62       1\n",
      " \n",
      "El 80% de ejemplos para entrenamiento son la cantidad de: 16278 de ejemplos\n",
      "El 20% de ejemplos para pruebas son la cantidad de: 4071 de ejemplos\n",
      "La cantidad total de ejemplos es de: 34000 de ejemplos\n"
     ]
    }
   ],
   "source": [
    "#estos datos seran usados para el entrenamiento\n",
    "X_testSR = X_test.copy()\n",
    "y_testSR = y_test.copy()\n",
    "m_test_SR = len(y_testSR)\n",
    "\n",
    "#estos datos seran usados para el test\n",
    "X_trainSR = X_train.copy()\n",
    "y_trainSR = y_train.copy()\n",
    "m_train_SR = len(y_trainSR)\n",
    "\n",
    "#Visualizamos una cantidad de datos de entrenamiento\n",
    "print('{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>6s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'X[:, 11]', 'X[:, 12]', \n",
    "    'X[:, 13]', 'X[:, 14]', 'X[:, 15]', 'X[:, 16]', 'X[:, 17]', 'X[:, 18]','Y'\n",
    "))\n",
    "print('-' * 250)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:8.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:10.0f}{:8.0f}'.format(\n",
    "        X_trainSR[i, 0],\n",
    "        X_trainSR[i, 1],\n",
    "        X_trainSR[i, 2], \n",
    "        X_trainSR[i, 3], \n",
    "        X_trainSR[i, 4], \n",
    "        X_trainSR[i, 5], \n",
    "        X_trainSR[i, 6], \n",
    "        X_trainSR[i, 7], \n",
    "        X_trainSR[i, 8], \n",
    "        X_trainSR[i, 9], \n",
    "        X_trainSR[i, 10],\n",
    "        X_trainSR[i, 11],\n",
    "        X_trainSR[i, 12], \n",
    "        X_trainSR[i, 13], \n",
    "        X_trainSR[i, 14], \n",
    "        X_trainSR[i, 15], \n",
    "        X_trainSR[i, 16],\n",
    "        X_trainSR[i, 17],\n",
    "        X_trainSR[i, 18],\n",
    "        y_trainSR[i]\n",
    "    ))\n",
    "\n",
    "print(\" \")\n",
    "print('El 80% de ejemplos para entrenamiento son la cantidad de: {:.0f} de ejemplos'.format( len(X_train)))\n",
    "print('El 20% de ejemplos para pruebas son la cantidad de: {:.0f} de ejemplos'.format( len(X_test)))\n",
    "print('La cantidad total de ejemplos es de: {:.0f} de ejemplos'.format( len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Normalizacion de las caracteristicas\n",
    "\n",
    "Se hace uso de la funcion de `featureNormalize(X) ` donde se recibe un parametro de tipo matriz para normalizar cada dato dentro de ella, retornandome la **matriz normalizda**, **sigma(desviacion estandar)**, y mi **mu(media)**.\n",
    "\n",
    "Almacenando los datos normalizados en **X_norm** usando la funcion **featureNormaliza()**, normalizando los datos de X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X[:,0]   X[:, 1]   X[:, 2]   X[:, 3]   X[:, 4]   X[:, 5]   X[:, 6]   X[:, 7]   X[:, 8]   X[:, 9]  X[:, 10]  X[:, 11]  X[:, 12]  X[:, 13]  X[:, 14]  X[:, 15]  X[:, 16]  X[:, 17]  X[:, 18]     Y\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "      1.02      0.45     -0.28      0.20     -1.15     -0.31     -0.93     -0.11      0.22     -0.77      0.98     -1.06     -0.91     -1.40      1.16     -1.66     -0.17      0.01     -0.21       0\n",
      "      0.10     -0.59     -1.65     -1.70     -1.69     -1.67      1.44     -1.42      0.82     -1.37     -0.90     -1.11     -1.44     -0.93      1.16     -0.24      0.70      0.98      1.22       1\n",
      "     -1.59      0.79      0.03      0.75      1.24     -1.05      0.63     -1.57      1.73      0.10      0.46     -0.07     -0.82     -0.34      0.07      0.45      0.31     -0.83     -0.65       0\n",
      "      0.97      1.53     -1.29      1.32      1.15      1.50      0.81      0.59      1.14     -0.61      1.42      0.14      1.10      1.34     -0.05     -0.34      1.51     -0.86      0.91       1\n",
      "     -0.78     -1.18     -0.98     -1.62     -0.64     -0.16      0.93      0.51      1.24      1.16      1.00      1.07     -0.64      0.40     -0.83      1.38      0.42      0.08     -0.79       1\n",
      "      1.47      0.97      1.70      1.29     -1.24     -1.30      0.19     -0.43      1.29      1.00     -1.03      0.75      1.64     -1.18     -0.84      1.56     -0.46     -0.17      0.08       2\n",
      "      1.07      0.43     -1.56     -0.33     -0.26     -1.25      0.41     -1.00      0.81      0.98      0.71     -1.55     -0.48      1.46      1.36      0.92      1.00     -1.09      0.90       0\n",
      "      0.70      0.52      1.22      0.60      0.86     -1.11      0.21     -0.14      0.72      1.73      1.67     -1.09     -1.39      1.29     -1.49     -0.93      0.15      0.57     -1.43       1\n",
      "      0.83     -0.47      0.69      1.40      0.89     -0.04      0.41     -0.56     -1.01      1.04      0.16     -1.14      0.48     -0.53     -0.34      0.93     -1.15     -0.22     -0.78       2\n",
      "     -1.02     -0.34     -0.82     -0.26     -0.79      0.03      0.18      0.11     -1.12      1.72      0.47     -0.56     -1.13     -1.60      0.32      0.68     -1.68      0.72     -0.63       1\n"
     ]
    }
   ],
   "source": [
    "X_norm_SR, mu_SR, sigma_SR = featureNormalize(X_trainSR)\n",
    "\n",
    "# imprimir todos las X_norm de datos solo 10\n",
    "print('{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>10s}{:>6s}'.format(\n",
    "    'X[:,0]', 'X[:, 1]', 'X[:, 2]', 'X[:, 3]', 'X[:, 4]', 'X[:, 5]', 'X[:, 6]', 'X[:, 7]', 'X[:, 8]', 'X[:, 9]', 'X[:, 10]', 'X[:, 11]', 'X[:, 12]', \n",
    "    'X[:, 13]', 'X[:, 14]', 'X[:, 15]', 'X[:, 16]', 'X[:, 17]', 'X[:, 18]','Y'\n",
    "))\n",
    "print('-' * 250)\n",
    "\n",
    "for i in range(10):\n",
    "    print('{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:10.2f}{:8.0f}'.format(\n",
    "        X_norm_SR[i, 0],\n",
    "        X_norm_SR[i, 1],\n",
    "        X_norm_SR[i, 2], \n",
    "        X_norm_SR[i, 3], \n",
    "        X_norm_SR[i, 4], \n",
    "        X_norm_SR[i, 5], \n",
    "        X_norm_SR[i, 6], \n",
    "        X_norm_SR[i, 7], \n",
    "        X_norm_SR[i, 8], \n",
    "        X_norm_SR[i, 9], \n",
    "        X_norm_SR[i, 10],\n",
    "        X_norm_SR[i, 11],\n",
    "        X_norm_SR[i, 12], \n",
    "        X_norm_SR[i, 13], \n",
    "        X_norm_SR[i, 14], \n",
    "        X_norm_SR[i, 15], \n",
    "        X_norm_SR[i, 16],\n",
    "        X_norm_SR[i, 17],\n",
    "        X_norm_SR[i, 18], \n",
    "        y_trainSR[i]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Clasificacion One-vs-All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 20)\n",
      "Thetha 0  para la clase 0: -0.7042618244212244  ;  Thetha 0  para la clase 1: -0.6881572342372574  ;  Thetha 0  para la clase 2: -0.6892960056066103  ;  Thetha 0  para la clase 3: -12.438080489184117  ;  Thetha 0  para la clase 4: -12.438080489184117\n",
      "Thetha 1  para la clase 0: 0.00991582955285187  ;  Thetha 1  para la clase 1: -0.017807741696226547  ;  Thetha 1  para la clase 2: 0.00796920980010069  ;  Thetha 1  para la clase 3: 5.94017094920677e-15  ;  Thetha 1  para la clase 4: 5.94017094920677e-15\n",
      "Thetha 2  para la clase 0: -0.007628770743671999  ;  Thetha 2  para la clase 1: 0.010893115981282512  ;  Thetha 2  para la clase 2: -0.003317458049881673  ;  Thetha 2  para la clase 3: 8.964209424816952e-15  ;  Thetha 2  para la clase 4: 8.964209424816952e-15\n",
      "Thetha 3  para la clase 0: -0.012032768705615947  ;  Thetha 3  para la clase 1: -0.003982732929672475  ;  Thetha 3  para la clase 2: 0.01593685217757366  ;  Thetha 3  para la clase 3: 4.853017817027091e-16  ;  Thetha 3  para la clase 4: 4.853017817027091e-16\n",
      "Thetha 4  para la clase 0: 0.012384930764363509  ;  Thetha 4  para la clase 1: -0.0120169229331303  ;  Thetha 4  para la clase 2: -0.00030447793405628126  ;  Thetha 4  para la clase 3: 7.741545101421904e-15  ;  Thetha 4  para la clase 4: 7.741545101421904e-15\n",
      "Thetha 5  para la clase 0: 0.012419579081777779  ;  Thetha 5  para la clase 1: -0.018248633424367007  ;  Thetha 5  para la clase 2: 0.00590030126761258  ;  Thetha 5  para la clase 3: -1.046482848346822e-14  ;  Thetha 5  para la clase 4: -1.046482848346822e-14\n",
      "Thetha 6  para la clase 0: 0.010712403900071265  ;  Thetha 6  para la clase 1: -0.003798730049402727  ;  Thetha 6  para la clase 2: -0.006878121325091383  ;  Thetha 6  para la clase 3: 1.0802141750541741e-15  ;  Thetha 6  para la clase 4: 1.0802141750541741e-15\n",
      "Thetha 7  para la clase 0: 0.029234779658402835  ;  Thetha 7  para la clase 1: 0.00873234419278841  ;  Thetha 7  para la clase 2: -0.03779314824435647  ;  Thetha 7  para la clase 3: 6.352211991415509e-15  ;  Thetha 7  para la clase 4: 6.352211991415509e-15\n",
      "Thetha 8  para la clase 0: -0.00791240382718424  ;  Thetha 8  para la clase 1: 0.00646438102828455  ;  Thetha 8  para la clase 2: 0.001396403051153163  ;  Thetha 8  para la clase 3: -1.0533077585649535e-14  ;  Thetha 8  para la clase 4: -1.0533077585649535e-14\n",
      "Thetha 9  para la clase 0: -0.028423263469397393  ;  Thetha 9  para la clase 1: 0.019727973362010733  ;  Thetha 9  para la clase 2: 0.008524175453545536  ;  Thetha 9  para la clase 3: -4.385895191408788e-15  ;  Thetha 9  para la clase 4: -4.385895191408788e-15\n",
      "Thetha 10  para la clase 0: -0.035794029838109837  ;  Thetha 10  para la clase 1: 0.024246409524035114  ;  Thetha 10  para la clase 2: 0.011321750375662411  ;  Thetha 10  para la clase 3: 2.3048799829632735e-14  ;  Thetha 10  para la clase 4: 2.3048799829632735e-14\n",
      "Thetha 11  para la clase 0: 0.012561665443021036  ;  Thetha 11  para la clase 1: 0.004809128875791933  ;  Thetha 11  para la clase 2: -0.017302527097970387  ;  Thetha 11  para la clase 3: 1.598553941412233e-14  ;  Thetha 11  para la clase 4: 1.598553941412233e-14\n",
      "Thetha 12  para la clase 0: -0.02619155343044643  ;  Thetha 12  para la clase 1: 0.008024320057374901  ;  Thetha 12  para la clase 2: 0.018009465852014017  ;  Thetha 12  para la clase 3: 1.4626714444048777e-15  ;  Thetha 12  para la clase 4: 1.4626714444048777e-15\n",
      "Thetha 13  para la clase 0: -0.016019456630382203  ;  Thetha 13  para la clase 1: 0.003847142738101486  ;  Thetha 13  para la clase 2: 0.01204886704688275  ;  Thetha 13  para la clase 3: 5.173221775956843e-15  ;  Thetha 13  para la clase 4: 5.173221775956843e-15\n",
      "Thetha 14  para la clase 0: 0.01480159978844718  ;  Thetha 14  para la clase 1: -0.008930120521424147  ;  Thetha 14  para la clase 2: -0.005784035174300171  ;  Thetha 14  para la clase 3: 2.919516908893952e-15  ;  Thetha 14  para la clase 4: 2.919516908893952e-15\n",
      "Thetha 15  para la clase 0: -0.00700813790236766  ;  Thetha 15  para la clase 1: -0.012792622864921388  ;  Thetha 15  para la clase 2: 0.01973352337832129  ;  Thetha 15  para la clase 3: 3.6770172340335314e-16  ;  Thetha 15  para la clase 4: 3.6770172340335314e-16\n",
      "Thetha 16  para la clase 0: -0.022109990179594807  ;  Thetha 16  para la clase 1: 0.01582986030442437  ;  Thetha 16  para la clase 2: 0.006146413396764366  ;  Thetha 16  para la clase 3: -3.0671467864245167e-15  ;  Thetha 16  para la clase 4: -3.0671467864245167e-15\n",
      "Thetha 17  para la clase 0: -0.0029238832391647014  ;  Thetha 17  para la clase 1: -0.004273654839685143  ;  Thetha 17  para la clase 2: 0.0072080474017754016  ;  Thetha 17  para la clase 3: 4.900925331505954e-15  ;  Thetha 17  para la clase 4: 4.900925331505954e-15\n",
      "Thetha 18  para la clase 0: 0.026532391194670102  ;  Thetha 18  para la clase 1: -0.014388786845206152  ;  Thetha 18  para la clase 2: -0.011967858395041798  ;  Thetha 18  para la clase 3: 1.6455565864183584e-15  ;  Thetha 18  para la clase 4: 1.6455565864183584e-15\n",
      "Thetha 19  para la clase 0: -0.024372120834318434  ;  Thetha 19  para la clase 1: 0.019702889182417496  ;  Thetha 19  para la clase 2: 0.0045028960104445785  ;  Thetha 19  para la clase 3: 8.516504459652079e-15  ;  Thetha 19  para la clase 4: 8.516504459652079e-15\n"
     ]
    }
   ],
   "source": [
    "all_theta_SR = oneVsAllSR(X_norm_SR, y_trainSR, num_labels)\n",
    "print(all_theta_CR.shape)\n",
    "\n",
    "#imprimimos todos los thetas para cada clase\n",
    "for i in range(all_theta_SR.shape[1]):\n",
    "    print(\"Thetha\",i,\" para la clase 0:\", all_theta_SR[0,i],\" ; \", \"Thetha\",i,\" para la clase 1:\", all_theta_SR[1,i],\" ; \", \"Thetha\",i,\" para la clase 2:\", all_theta_SR[2,i] , \" ; \", \"Thetha\",i,\" para la clase 3:\", all_theta_SR[3,i],\" ; \", \"Thetha\",i,\" para la clase 4:\", all_theta_SR[4,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Validaciones\n",
    "Para hacer las validaciones correspondientes se hizo el uso siguiendo el consejo de 80/20, donde 80% es para la fase de entrenamiento, y 20% es para la fase de prueba.\n",
    "\n",
    "Para este caso de validacion se hizo uso de la funcion de `predictOneVsAll()` creada anteriormente, los siguiente fue normalizar nuestra `X_test` que son el 20% para pruebas, ahora se procedio a normalizarlo haciendo uso de *mu* y *sigma* calculado anteriormente en la funcion de normalizacion.\n",
    "\n",
    "luego se hace uso de `np.mean` donde nos calcula el promedio de los valores booleanos en el array resultante de la comparación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Con los datos de entrenamiento\n",
    "Para este caso se uso los datos de `X_norm` usando la funcion de `predictOneVsAll()`, viendo el resultado de precision nos da un **34.91829%** el cual esta muy lejos de ser un buen modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del conjunto de entrenamiento: 34.91829%\n"
     ]
    }
   ],
   "source": [
    "# print(X_test.shape)\n",
    "pred_test_SR = predictOneVsAll(all_theta_SR, X_norm_SR)\n",
    "print('Precision del conjunto de entrenamiento: {:.5f}%'.format(np.mean(pred_test_SR == y_trainSR) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 con los datos de prueba\n",
    "Para este caso se uso los datos de `X_test`, luego se procedio a normalizar los datos. \n",
    "\n",
    "Usando la funcion de `predictOneVsAll()`, viendo el resultado de precision nos da un **34.34046%** , un poco en diferencia a la anterior prediccion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision del conjunto de entrenamiento: 34.34046%\n"
     ]
    }
   ],
   "source": [
    "X_test1_SR = X_testSR.copy()\n",
    "# print(X_test.shape)\n",
    "X_test1_SR = (X_test1_SR - mu_SR) / sigma_SR\n",
    "pred_train_SR = predictOneVsAll(all_theta_SR, X_test1_SR)\n",
    "print('Precision del conjunto de entrenamiento: {:.5f}%'.format(np.mean(pred_train_SR == y_testSR) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se puede hacer las predicciones usando directamente la funcion `sigmoid()`, y luego imprimimos 30 predicciones para ver que tanto se asemejan con nuestra Y predicha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4071, 20)\n",
      "Prediccion: 0, Real: 0.0\n",
      "Prediccion: 2, Real: 0.0\n",
      "Prediccion: 1, Real: 0.0\n",
      "Prediccion: 0, Real: 2.0\n",
      "Prediccion: 0, Real: 0.0\n",
      "Prediccion: 0, Real: 2.0\n",
      "Prediccion: 0, Real: 0.0\n",
      "Prediccion: 2, Real: 0.0\n",
      "Prediccion: 1, Real: 0.0\n",
      "Prediccion: 0, Real: 1.0\n",
      "Prediccion: 2, Real: 1.0\n",
      "Prediccion: 0, Real: 2.0\n",
      "Prediccion: 0, Real: 2.0\n",
      "Prediccion: 0, Real: 0.0\n",
      "Prediccion: 2, Real: 1.0\n",
      "Prediccion: 1, Real: 1.0\n",
      "Prediccion: 1, Real: 0.0\n",
      "Prediccion: 0, Real: 1.0\n",
      "Prediccion: 1, Real: 1.0\n",
      "Prediccion: 1, Real: 1.0\n",
      "Prediccion: 1, Real: 1.0\n",
      "Prediccion: 0, Real: 2.0\n",
      "Prediccion: 1, Real: 0.0\n",
      "Prediccion: 0, Real: 1.0\n",
      "Prediccion: 1, Real: 2.0\n",
      "Prediccion: 1, Real: 0.0\n",
      "Prediccion: 0, Real: 0.0\n",
      "Prediccion: 1, Real: 0.0\n",
      "Prediccion: 2, Real: 1.0\n",
      "Prediccion: 2, Real: 0.0\n"
     ]
    }
   ],
   "source": [
    "#usando el mu y sigma calculado anteriormente, para realizar la normalizacion de los datos de prueba\n",
    "X_test1_SR = (X_testSR.copy() - mu_SR) / sigma_SR\n",
    "X_test1_SR = np.concatenate([np.ones((len(X_test1_SR), 1)), X_test1_SR], axis=1)\n",
    "\n",
    "print(X_test1_SR.shape)\n",
    "\n",
    "#para este ejemplo, vamos a mostrar las predicciones de las primeras 30 predicciones y compararlas con las reales\n",
    "p = np.argmax(sigmoid(X_test1_SR.dot(all_theta_SR.T)), axis = 1)\n",
    "\n",
    "for i in range(30):\n",
    "    print(f\"Prediccion: {p[i]}, Real: {y_test[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "En esta parte se presentaran las conclusiones de acuerdo a las experiencias vistas en este laboratorio aplicando regularizacion y sin aplicar regularizacion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Impacto de la regularización en la precisión del modelo:\n",
    "\n",
    " Se observa que la regularización puede tener un efecto en la precisión del modelo. En algunos casos, la regularización puede mejorar la precisión del modelo al reducir el sobreajuste (overfitting),\n",
    " especialmente cuando se tienen conjuntos de datos pequeños o altamente ruidosos. \n",
    " \n",
    " Sin embargo, en conjuntos de datos más grandes o con menos ruido, la regularización puede no proporcionar mejoras significativas en la precisión y podría incluso degradarla.\n",
    "\n",
    " Para este caso se hizo la comparacion entre la preciscion de ambos modelos, con y sin regularizacion:\n",
    "\n",
    "| Tipo  | Precision del modelo con regularizacion| Presicion del modelo sin regularizacion| Dieferencia entre ambos|\n",
    "|---------|------|---------|-----------|\n",
    "| Con los datos de entrenamiento |34.83843%  | 34.91829% | -0.07986% |\n",
    "| Con los datos de prueba | 34.36502%  | 34.34046% | 0.02456% |\n",
    "\n",
    "Sepodemos observar que tanto la precisión del modelo con regularización como la del modelo sin regularización son bastante similares en ambos conjuntos de datos, tanto en los datos de entrenamiento como en los de prueba. Sin embargo, hay una ligera diferencia entre ambos en cada conjunto de datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
