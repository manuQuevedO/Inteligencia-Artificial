{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG47R3-68bqb"
      },
      "source": [
        "Para el laboratorio hizo uso del para entrenar el modelo de **Redes neuronales** y predecir el número de veces que se comparten en redes sociales (popularidad).\n",
        "\n",
        "El enlace al dataset es [Online News Popularity](https://archive.ics.uci.edu/dataset/332/online+news+popularity).\n",
        "\n",
        "El archivo `OnlineNewsPopularity.csv` conjunto de datos resume un conjunto heterogéneo de características sobre artículos publicados por Mashable en un período de dos años. El objetivo es predecir el número de veces que se comparten en redes sociales (popularidad)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtI8krjJ8bqb"
      },
      "source": [
        "Importamos la librerias necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ad6suGJF8bqc"
      },
      "outputs": [],
      "source": [
        "# used for manipulating directory paths\n",
        "import os\n",
        "\n",
        "# Scientific and vector computation for python\n",
        "import numpy as np\n",
        "\n",
        "# Plotting library\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# Optimization module in scipy\n",
        "from scipy import optimize\n",
        "\n",
        "# will be used to load MATLAB mat datafile format\n",
        "from scipy.io import loadmat\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "#esta tabulate nos sirve para hacer tablas\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Librerias para graficación (trazado de gráficos)\n",
        "from matplotlib import pyplot\n",
        "# tells matplotlib to embed plots within the notebook\n",
        "\n",
        "#Para separa el 20% y 80%\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6AndErF8bqc"
      },
      "source": [
        "# Red nueronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "5GmcZ0148bqc",
        "outputId": "badd1e2d-ca40-4061-b36c-6c9ff74f4a25"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>timedelta</th>\n",
              "      <th>n_tokens_title</th>\n",
              "      <th>n_tokens_content</th>\n",
              "      <th>n_unique_tokens</th>\n",
              "      <th>n_non_stop_words</th>\n",
              "      <th>n_non_stop_unique_tokens</th>\n",
              "      <th>num_hrefs</th>\n",
              "      <th>num_self_hrefs</th>\n",
              "      <th>num_imgs</th>\n",
              "      <th>...</th>\n",
              "      <th>min_positive_polarity</th>\n",
              "      <th>max_positive_polarity</th>\n",
              "      <th>avg_negative_polarity</th>\n",
              "      <th>min_negative_polarity</th>\n",
              "      <th>max_negative_polarity</th>\n",
              "      <th>title_subjectivity</th>\n",
              "      <th>title_sentiment_polarity</th>\n",
              "      <th>abs_title_subjectivity</th>\n",
              "      <th>abs_title_sentiment_polarity</th>\n",
              "      <th>shares</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32340</th>\n",
              "      <td>http://mashable.com/2014/09/08/safest-cabbies-...</td>\n",
              "      <td>121</td>\n",
              "      <td>12</td>\n",
              "      <td>1015</td>\n",
              "      <td>0.422018</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.545031</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>33</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.8</td>\n",
              "      <td>-0.160714</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.071429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10480</th>\n",
              "      <td>http://mashable.com/2013/07/25/3d-printed-rifle/</td>\n",
              "      <td>532</td>\n",
              "      <td>9</td>\n",
              "      <td>503</td>\n",
              "      <td>0.569697</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.737542</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.157500</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15370</th>\n",
              "      <td>http://mashable.com/2013/10/30/digital-dinosau...</td>\n",
              "      <td>435</td>\n",
              "      <td>9</td>\n",
              "      <td>232</td>\n",
              "      <td>0.646018</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.748428</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.427500</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.187500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>17700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31592</th>\n",
              "      <td>http://mashable.com/2014/08/27/homer-simpson-i...</td>\n",
              "      <td>134</td>\n",
              "      <td>12</td>\n",
              "      <td>171</td>\n",
              "      <td>0.722892</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.867925</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.216667</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>http://mashable.com/2013/01/10/creepy-robotic-...</td>\n",
              "      <td>728</td>\n",
              "      <td>11</td>\n",
              "      <td>286</td>\n",
              "      <td>0.652632</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.251786</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9922</th>\n",
              "      <td>http://mashable.com/2013/07/15/elon-musk-hyper...</td>\n",
              "      <td>542</td>\n",
              "      <td>9</td>\n",
              "      <td>532</td>\n",
              "      <td>0.558577</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.644118</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.310000</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20296</th>\n",
              "      <td>http://mashable.com/2014/02/12/derek-jeter-ret...</td>\n",
              "      <td>330</td>\n",
              "      <td>11</td>\n",
              "      <td>1125</td>\n",
              "      <td>0.393178</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.561129</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.152192</td>\n",
              "      <td>-0.700000</td>\n",
              "      <td>-0.008333</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.095833</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.095833</td>\n",
              "      <td>812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14010</th>\n",
              "      <td>http://mashable.com/2013/10/03/salt-ship-design/</td>\n",
              "      <td>462</td>\n",
              "      <td>10</td>\n",
              "      <td>850</td>\n",
              "      <td>0.435583</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.571977</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>21</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.178788</td>\n",
              "      <td>-0.291667</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39479</th>\n",
              "      <td>http://mashable.com/2014/12/23/tablets-messing...</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>1250</td>\n",
              "      <td>0.452145</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.639300</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.289641</td>\n",
              "      <td>-0.700000</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10294</th>\n",
              "      <td>http://mashable.com/2013/07/22/diy-projects/</td>\n",
              "      <td>535</td>\n",
              "      <td>10</td>\n",
              "      <td>271</td>\n",
              "      <td>0.571970</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.765957</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.126389</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>2700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 38 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     url   timedelta  \\\n",
              "32340  http://mashable.com/2014/09/08/safest-cabbies-...         121   \n",
              "10480   http://mashable.com/2013/07/25/3d-printed-rifle/         532   \n",
              "15370  http://mashable.com/2013/10/30/digital-dinosau...         435   \n",
              "31592  http://mashable.com/2014/08/27/homer-simpson-i...         134   \n",
              "198    http://mashable.com/2013/01/10/creepy-robotic-...         728   \n",
              "...                                                  ...         ...   \n",
              "9922   http://mashable.com/2013/07/15/elon-musk-hyper...         542   \n",
              "20296  http://mashable.com/2014/02/12/derek-jeter-ret...         330   \n",
              "14010   http://mashable.com/2013/10/03/salt-ship-design/         462   \n",
              "39479  http://mashable.com/2014/12/23/tablets-messing...          12   \n",
              "10294       http://mashable.com/2013/07/22/diy-projects/         535   \n",
              "\n",
              "        n_tokens_title   n_tokens_content   n_unique_tokens  \\\n",
              "32340               12               1015          0.422018   \n",
              "10480                9                503          0.569697   \n",
              "15370                9                232          0.646018   \n",
              "31592               12                171          0.722892   \n",
              "198                 11                286          0.652632   \n",
              "...                ...                ...               ...   \n",
              "9922                 9                532          0.558577   \n",
              "20296               11               1125          0.393178   \n",
              "14010               10                850          0.435583   \n",
              "39479                8               1250          0.452145   \n",
              "10294               10                271          0.571970   \n",
              "\n",
              "        n_non_stop_words   n_non_stop_unique_tokens   num_hrefs  \\\n",
              "32340                1.0                   0.545031          10   \n",
              "10480                1.0                   0.737542           9   \n",
              "15370                1.0                   0.748428          12   \n",
              "31592                1.0                   0.867925           9   \n",
              "198                  1.0                   0.800000           5   \n",
              "...                  ...                        ...         ...   \n",
              "9922                 1.0                   0.644118          20   \n",
              "20296                1.0                   0.561129           5   \n",
              "14010                1.0                   0.571977           7   \n",
              "39479                1.0                   0.639300          19   \n",
              "10294                1.0                   0.765957           1   \n",
              "\n",
              "        num_self_hrefs   num_imgs  ...   min_positive_polarity  \\\n",
              "32340                6         33  ...                0.100000   \n",
              "10480                0          1  ...                0.136364   \n",
              "15370                3          4  ...                0.375000   \n",
              "31592                5          0  ...                0.500000   \n",
              "198                  2          0  ...                0.100000   \n",
              "...                ...        ...  ...                     ...   \n",
              "9922                 3         15  ...                0.100000   \n",
              "20296                3          4  ...                0.100000   \n",
              "14010                6         21  ...                0.100000   \n",
              "39479                0          1  ...                0.033333   \n",
              "10294                1          1  ...                0.136364   \n",
              "\n",
              "        max_positive_polarity   avg_negative_polarity   min_negative_polarity  \\\n",
              "32340                     0.8               -0.160714               -0.500000   \n",
              "10480                     1.0               -0.157500               -0.250000   \n",
              "15370                     0.5               -0.427500               -1.000000   \n",
              "31592                     0.5               -0.216667               -0.250000   \n",
              "198                       0.6               -0.251786               -0.500000   \n",
              "...                       ...                     ...                     ...   \n",
              "9922                      1.0               -0.310000               -0.600000   \n",
              "20296                     1.0               -0.152192               -0.700000   \n",
              "14010                     1.0               -0.178788               -0.291667   \n",
              "39479                     1.0               -0.289641               -0.700000   \n",
              "10294                     0.5               -0.126389               -0.166667   \n",
              "\n",
              "        max_negative_polarity   title_subjectivity   title_sentiment_polarity  \\\n",
              "32340               -0.071429             0.000000                   0.000000   \n",
              "10480               -0.100000             0.000000                   0.000000   \n",
              "15370               -0.187500             0.000000                   0.000000   \n",
              "31592               -0.166667             0.400000                  -0.250000   \n",
              "198                 -0.100000             0.200000                  -0.100000   \n",
              "...                       ...                  ...                        ...   \n",
              "9922                -0.100000             0.000000                   0.000000   \n",
              "20296               -0.008333             0.050000                   0.095833   \n",
              "14010               -0.100000             0.000000                   0.000000   \n",
              "39479               -0.100000             0.000000                   0.000000   \n",
              "10294               -0.100000             0.642857                   0.214286   \n",
              "\n",
              "        abs_title_subjectivity   abs_title_sentiment_polarity   shares  \n",
              "32340                 0.500000                       0.000000     2900  \n",
              "10480                 0.500000                       0.000000     1300  \n",
              "15370                 0.500000                       0.000000    17700  \n",
              "31592                 0.100000                       0.250000     1500  \n",
              "198                   0.300000                       0.100000     1400  \n",
              "...                        ...                            ...      ...  \n",
              "9922                  0.500000                       0.000000     4600  \n",
              "20296                 0.450000                       0.095833      812  \n",
              "14010                 0.500000                       0.000000     1400  \n",
              "39479                 0.500000                       0.000000     1000  \n",
              "10294                 0.142857                       0.214286     2700  \n",
              "\n",
              "[20000 rows x 38 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = pd.read_csv('OnlineNewsPopularity.csv', delimiter=',')\n",
        "\n",
        "\n",
        "# dataset = pd.read_csv('OnlineNewsPopularity.csv', delimiter=',')\n",
        "#para usarlo a travez de google colab\n",
        "dataset = dataset.sample(n=20000, random_state=42)\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRIcDdkO8bqd"
      },
      "source": [
        "## Tratamiento de datos\n",
        "\n",
        "vamos a eliminar las columnas de nuestro dataset que no necesitamos, en este caso la direccion de url:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "9K197ebR8bqd",
        "outputId": "8fcce8ed-ee1d-4d8f-a1d4-db991d187bff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timedelta</th>\n",
              "      <th>n_tokens_title</th>\n",
              "      <th>n_tokens_content</th>\n",
              "      <th>n_unique_tokens</th>\n",
              "      <th>n_non_stop_words</th>\n",
              "      <th>n_non_stop_unique_tokens</th>\n",
              "      <th>num_hrefs</th>\n",
              "      <th>num_self_hrefs</th>\n",
              "      <th>num_imgs</th>\n",
              "      <th>num_videos</th>\n",
              "      <th>...</th>\n",
              "      <th>min_positive_polarity</th>\n",
              "      <th>max_positive_polarity</th>\n",
              "      <th>avg_negative_polarity</th>\n",
              "      <th>min_negative_polarity</th>\n",
              "      <th>max_negative_polarity</th>\n",
              "      <th>title_subjectivity</th>\n",
              "      <th>title_sentiment_polarity</th>\n",
              "      <th>abs_title_subjectivity</th>\n",
              "      <th>abs_title_sentiment_polarity</th>\n",
              "      <th>shares</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32340</th>\n",
              "      <td>121</td>\n",
              "      <td>12</td>\n",
              "      <td>1015</td>\n",
              "      <td>0.422018</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.545031</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.8</td>\n",
              "      <td>-0.160714</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.071429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10480</th>\n",
              "      <td>532</td>\n",
              "      <td>9</td>\n",
              "      <td>503</td>\n",
              "      <td>0.569697</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.737542</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.157500</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15370</th>\n",
              "      <td>435</td>\n",
              "      <td>9</td>\n",
              "      <td>232</td>\n",
              "      <td>0.646018</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.748428</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.427500</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.187500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>17700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31592</th>\n",
              "      <td>134</td>\n",
              "      <td>12</td>\n",
              "      <td>171</td>\n",
              "      <td>0.722892</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.867925</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.216667</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>728</td>\n",
              "      <td>11</td>\n",
              "      <td>286</td>\n",
              "      <td>0.652632</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.6</td>\n",
              "      <td>-0.251786</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9922</th>\n",
              "      <td>542</td>\n",
              "      <td>9</td>\n",
              "      <td>532</td>\n",
              "      <td>0.558577</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.644118</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>21</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.310000</td>\n",
              "      <td>-0.600000</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20296</th>\n",
              "      <td>330</td>\n",
              "      <td>11</td>\n",
              "      <td>1125</td>\n",
              "      <td>0.393178</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.561129</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.152192</td>\n",
              "      <td>-0.700000</td>\n",
              "      <td>-0.008333</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.095833</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.095833</td>\n",
              "      <td>812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14010</th>\n",
              "      <td>462</td>\n",
              "      <td>10</td>\n",
              "      <td>850</td>\n",
              "      <td>0.435583</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.571977</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.178788</td>\n",
              "      <td>-0.291667</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39479</th>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>1250</td>\n",
              "      <td>0.452145</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.639300</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.289641</td>\n",
              "      <td>-0.700000</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10294</th>\n",
              "      <td>535</td>\n",
              "      <td>10</td>\n",
              "      <td>271</td>\n",
              "      <td>0.571970</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.765957</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.126389</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>2700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 37 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
              "32340        121              12              1015         0.422018   \n",
              "10480        532               9               503         0.569697   \n",
              "15370        435               9               232         0.646018   \n",
              "31592        134              12               171         0.722892   \n",
              "198          728              11               286         0.652632   \n",
              "...          ...             ...               ...              ...   \n",
              "9922         542               9               532         0.558577   \n",
              "20296        330              11              1125         0.393178   \n",
              "14010        462              10               850         0.435583   \n",
              "39479         12               8              1250         0.452145   \n",
              "10294        535              10               271         0.571970   \n",
              "\n",
              "       n_non_stop_words  n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  \\\n",
              "32340               1.0                  0.545031         10               6   \n",
              "10480               1.0                  0.737542          9               0   \n",
              "15370               1.0                  0.748428         12               3   \n",
              "31592               1.0                  0.867925          9               5   \n",
              "198                 1.0                  0.800000          5               2   \n",
              "...                 ...                       ...        ...             ...   \n",
              "9922                1.0                  0.644118         20               3   \n",
              "20296               1.0                  0.561129          5               3   \n",
              "14010               1.0                  0.571977          7               6   \n",
              "39479               1.0                  0.639300         19               0   \n",
              "10294               1.0                  0.765957          1               1   \n",
              "\n",
              "       num_imgs  num_videos  ...  min_positive_polarity  \\\n",
              "32340        33           1  ...               0.100000   \n",
              "10480         1           1  ...               0.136364   \n",
              "15370         4           1  ...               0.375000   \n",
              "31592         0           1  ...               0.500000   \n",
              "198           0           0  ...               0.100000   \n",
              "...         ...         ...  ...                    ...   \n",
              "9922         15          21  ...               0.100000   \n",
              "20296         4           1  ...               0.100000   \n",
              "14010        21           0  ...               0.100000   \n",
              "39479         1           0  ...               0.033333   \n",
              "10294         1           0  ...               0.136364   \n",
              "\n",
              "       max_positive_polarity  avg_negative_polarity  min_negative_polarity  \\\n",
              "32340                    0.8              -0.160714              -0.500000   \n",
              "10480                    1.0              -0.157500              -0.250000   \n",
              "15370                    0.5              -0.427500              -1.000000   \n",
              "31592                    0.5              -0.216667              -0.250000   \n",
              "198                      0.6              -0.251786              -0.500000   \n",
              "...                      ...                    ...                    ...   \n",
              "9922                     1.0              -0.310000              -0.600000   \n",
              "20296                    1.0              -0.152192              -0.700000   \n",
              "14010                    1.0              -0.178788              -0.291667   \n",
              "39479                    1.0              -0.289641              -0.700000   \n",
              "10294                    0.5              -0.126389              -0.166667   \n",
              "\n",
              "       max_negative_polarity  title_subjectivity  title_sentiment_polarity  \\\n",
              "32340              -0.071429            0.000000                  0.000000   \n",
              "10480              -0.100000            0.000000                  0.000000   \n",
              "15370              -0.187500            0.000000                  0.000000   \n",
              "31592              -0.166667            0.400000                 -0.250000   \n",
              "198                -0.100000            0.200000                 -0.100000   \n",
              "...                      ...                 ...                       ...   \n",
              "9922               -0.100000            0.000000                  0.000000   \n",
              "20296              -0.008333            0.050000                  0.095833   \n",
              "14010              -0.100000            0.000000                  0.000000   \n",
              "39479              -0.100000            0.000000                  0.000000   \n",
              "10294              -0.100000            0.642857                  0.214286   \n",
              "\n",
              "       abs_title_subjectivity  abs_title_sentiment_polarity  shares  \n",
              "32340                0.500000                      0.000000    2900  \n",
              "10480                0.500000                      0.000000    1300  \n",
              "15370                0.500000                      0.000000   17700  \n",
              "31592                0.100000                      0.250000    1500  \n",
              "198                  0.300000                      0.100000    1400  \n",
              "...                       ...                           ...     ...  \n",
              "9922                 0.500000                      0.000000    4600  \n",
              "20296                0.450000                      0.095833     812  \n",
              "14010                0.500000                      0.000000    1400  \n",
              "39479                0.500000                      0.000000    1000  \n",
              "10294                0.142857                      0.214286    2700  \n",
              "\n",
              "[20000 rows x 37 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#dropeamos la columna de url\n",
        "dataset = dataset.drop(['url'], axis=1)\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIC6Eegg8bqd"
      },
      "source": [
        "## Analisis del dataset\n",
        "\n",
        "para tener una mejor vista del los tipos de datos del dataset, hacemos un `info()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L2lR4168bqe",
        "outputId": "afed5d81-e060-4d18-9d97-7f420c2d437b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 20000 entries, 32340 to 10294\n",
            "Data columns (total 37 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0    timedelta                     20000 non-null  int64  \n",
            " 1    n_tokens_title                20000 non-null  int64  \n",
            " 2    n_tokens_content              20000 non-null  int64  \n",
            " 3    n_unique_tokens               20000 non-null  float64\n",
            " 4    n_non_stop_words              20000 non-null  float64\n",
            " 5    n_non_stop_unique_tokens      20000 non-null  float64\n",
            " 6    num_hrefs                     20000 non-null  int64  \n",
            " 7    num_self_hrefs                20000 non-null  int64  \n",
            " 8    num_imgs                      20000 non-null  int64  \n",
            " 9    num_videos                    20000 non-null  int64  \n",
            " 10   average_token_length          20000 non-null  float64\n",
            " 11   num_keywords                  20000 non-null  int64  \n",
            " 12   self_reference_min_shares     20000 non-null  float64\n",
            " 13   self_reference_max_shares     20000 non-null  float64\n",
            " 14   self_reference_avg_sharess    20000 non-null  float64\n",
            " 15   LDA_00                        20000 non-null  float64\n",
            " 16   LDA_01                        20000 non-null  float64\n",
            " 17   LDA_02                        20000 non-null  float64\n",
            " 18   LDA_03                        20000 non-null  float64\n",
            " 19   LDA_04                        20000 non-null  float64\n",
            " 20   global_subjectivity           20000 non-null  float64\n",
            " 21   global_sentiment_polarity     20000 non-null  float64\n",
            " 22   global_rate_positive_words    20000 non-null  float64\n",
            " 23   global_rate_negative_words    20000 non-null  float64\n",
            " 24   rate_positive_words           20000 non-null  float64\n",
            " 25   rate_negative_words           20000 non-null  float64\n",
            " 26   avg_positive_polarity         20000 non-null  float64\n",
            " 27   min_positive_polarity         20000 non-null  float64\n",
            " 28   max_positive_polarity         20000 non-null  float64\n",
            " 29   avg_negative_polarity         20000 non-null  float64\n",
            " 30   min_negative_polarity         20000 non-null  float64\n",
            " 31   max_negative_polarity         20000 non-null  float64\n",
            " 32   title_subjectivity            20000 non-null  float64\n",
            " 33   title_sentiment_polarity      20000 non-null  float64\n",
            " 34   abs_title_subjectivity        20000 non-null  float64\n",
            " 35   abs_title_sentiment_polarity  20000 non-null  float64\n",
            " 36   shares                        20000 non-null  int64  \n",
            "dtypes: float64(28), int64(9)\n",
            "memory usage: 5.8 MB\n"
          ]
        }
      ],
      "source": [
        "dataset.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6qhVBGk8bqe"
      },
      "source": [
        "podemo notar que todos son de tipo float, por lo cual no nos traera problemas al momento de entrenar el modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF48XaO48bqe"
      },
      "source": [
        "## Separacion del 80% de los datos para entrenamiento y 20% para pruebas\n",
        "\n",
        "Haremos uso de la libreria `sklearn` haciendo uso de su funcion `train_test_split()`, donde recibe como parametros:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7oravS78bqe",
        "outputId": "bc1f5a49-16b9-4594-9014-36fbb0cec4ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[5.77000000e+02 1.10000000e+01 4.76000000e+02 ... 1.36363636e-01\n",
            "  4.54545450e-02 1.36363636e-01]\n",
            " [1.28000000e+02 9.00000000e+00 8.77000000e+02 ... 1.00000000e-01\n",
            "  5.00000000e-01 1.00000000e-01]\n",
            " [6.71000000e+02 6.00000000e+00 1.42200000e+03 ... 5.00000000e-01\n",
            "  5.00000000e-01 5.00000000e-01]\n",
            " ...\n",
            " [1.56000000e+02 1.10000000e+01 4.92000000e+02 ... 0.00000000e+00\n",
            "  5.00000000e-01 0.00000000e+00]\n",
            " [4.22000000e+02 1.30000000e+01 9.86000000e+02 ... 0.00000000e+00\n",
            "  5.00000000e-01 0.00000000e+00]\n",
            " [4.12000000e+02 1.00000000e+01 1.94000000e+02 ... 8.00000000e-01\n",
            "  5.00000000e-01 8.00000000e-01]]\n",
            "[ 542 1000 3400 ...  950 3600 3100]\n"
          ]
        }
      ],
      "source": [
        "#separamos el 20% para test y el 80% para entrenamiento deld dataset\n",
        "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "# Seleccionamos las columnas para X y la columna 'shares' para y\n",
        "X_test = test_dataset.drop([' shares'], axis=1).values\n",
        "y_test = test_dataset[' shares'].values\n",
        "m_test = len(y_test)\n",
        "\n",
        "# Seleccionamos las columnas para X y la columna 'shares' para y\n",
        "X_train = train_dataset.drop([' shares'], axis=1).values\n",
        "y_train = train_dataset[' shares'].values\n",
        "m_train = len(y_train)\n",
        "# Ahora, X y y deberían contener datos numéricos del 80% del dataset\n",
        "\n",
        "\n",
        "\n",
        "# imprimir todos las X de datos solo 10\n",
        "print(X_train)\n",
        "print(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORiMeaLT8bqe",
        "outputId": "4efc68d7-e8aa-4ad5-a4fd-8505ae7acd05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "el 80% de datos es:16000 y el 20% es: 4000\n",
            "la totalidad de datos es:  20000\n"
          ]
        }
      ],
      "source": [
        "print(f\"el 80% de datos es:{X_train.shape[0]} y el 20% es: {X_test.shape[0]}\")\n",
        "print( \"la totalidad de datos es: \", dataset.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbGpo-C_8bqf",
        "outputId": "0a48b0e4-b285-4919-cb59-77a3c6725239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "la cantidad de columnas es:  36\n",
            "la cantidad de ejemplos es:  16000\n"
          ]
        }
      ],
      "source": [
        "### Usamos el shape para tener una imagen mas clara de las entradas\n",
        "\n",
        "#Con esta funcion podemos obtener la cantidad de caracteristicas que estamos usando y la cantidad de ejemplos que contiene nuestra matriz.\n",
        "\n",
        "print(\"la cantidad de columnas es: \", X_train.shape[1])\n",
        "print(\"la cantidad de ejemplos es: \", X_train.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edO9y0Rd8bqf"
      },
      "source": [
        "## capas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCn590yB8bqf",
        "outputId": "4a70fd09-2136-4c66-82e7-ff893b1dbc52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "capa de entrada es:  36\n",
            "capa de oculta es:  5\n",
            "capa de salida es:  1\n"
          ]
        }
      ],
      "source": [
        "# En este apartado definiremos la cantidad de capas que tendra el modelo:\n",
        "\n",
        "# - **Capa de entrada:** Es la cantidad de caracteristicas con las que cuenta el dataset.\n",
        "\n",
        "# - **Capa oculta:** esto se define haciendo pruebas.\n",
        "\n",
        "# - **Capa de salida:**como este modelo es de regresion lineal, se debe usar solo una capa de salida.\n",
        "\n",
        "# Configurando parametros necesario\n",
        "input_layer_size  = X_train.shape[1]  # Entrada de 36 caracteristicas,\n",
        "hidden_layer_size = 5   # 5 unidades ocultas en la capa oculta\n",
        "num_labels = 1          # solo se tiene una salida\n",
        "\n",
        "print(\"capa de entrada es: \",input_layer_size)\n",
        "print(\"capa de oculta es: \",hidden_layer_size)\n",
        "print(\"capa de salida es: \",num_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U86XZ_L-8bqf"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3eHmXjJS8bqf"
      },
      "outputs": [],
      "source": [
        "## Inicializacion de Thetas\n",
        "\n",
        "# Inicializamos los valores de theta1 y theta2 con valores aleatorios para evitar conflictos:\n",
        "# Los valores aleatorios aseguran que cada neurona pueda aprender patrones distintos, lo cual es crucial para el buen desempeño de la red.\n",
        "pesos = {}\n",
        "pesos['Theta1'] = np.random.rand(hidden_layer_size , input_layer_size + 1)\n",
        "pesos['Theta2'] = np.random.rand(num_labels, hidden_layer_size + 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzVTMk5O8bqf"
      },
      "source": [
        "### Guardamos los valores de theta en nuevas variables\n",
        "\n",
        "`.ravel()` Convertira las matrices Theta1 y Tetha2 en vectores unidimencionales.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAUckipj8bqf",
        "outputId": "48113e13-caec-480e-d30b-e913541c9fa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El tamaño de Theta1 es de:  (185,)\n",
            "El tamaño de Theta2 es de:  (6,)\n"
          ]
        }
      ],
      "source": [
        "# Al inicializar los pesos con valores aleatorios pequeños, se garantiza que las neuronas en una capa oculta comiencen a \n",
        "# aprender diferentes funciones. Esto aumenta la capacidad de representación de la red neuronal y permite que aprenda patrones \n",
        "# complejos en los datos de entrada. Además, la aleatorización ayuda a evitar que el algoritmo de aprendizaje se atasque en mínimos locales \n",
        "# subóptimos durante el entrenamiento.\n",
        "\n",
        "Theta1, Theta2 = pesos['Theta1'], pesos['Theta2']\n",
        "\n",
        "\n",
        "print(\"El tamaño de Theta1 es de: \",Theta1.ravel().shape)\n",
        "print(\"El tamaño de Theta2 es de: \",Theta2.ravel().shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xYqhbAo8bqg",
        "outputId": "a4e4fbbc-8bbf-44b3-ecbe-0d9f251dd9d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(191,)\n"
          ]
        }
      ],
      "source": [
        "## Concadenamos Theta1 y Theta2 para formar un solo array\n",
        "nn_params = np.concatenate([Theta1.ravel(), Theta2.ravel()])\n",
        "print(nn_params.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "83LFPlwu8bqg"
      },
      "outputs": [],
      "source": [
        "###               Funcion de activacion\n",
        "\n",
        "# Esta función simplemente pasa la entrada directamente a la salida sin aplicar ninguna transformación no lineal.\n",
        "\n",
        "def linear_activation(z):\n",
        "    return z\n",
        "\n",
        "def linear_gradient(z):\n",
        "    return np.ones_like(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a9VtELL8bqg"
      },
      "source": [
        "## Funcion de costo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5hvzhZH-o_-",
        "outputId": "38e96852-ad51-4b0e-f92a-8602462cd925"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(191,)\n"
          ]
        }
      ],
      "source": [
        "print(nn_params.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "H8_YdprL8bqg"
      },
      "outputs": [],
      "source": [
        "# permite saber si el modelo está haciendo un buen trabajo al comparar las predicciones del modelo con los valores reales que deberían ser.\n",
        "\n",
        "# la regularización se utiliza en dos lugares principales para ayudar a prevenir el sobreajuste modificando tanto el cálculo del costo como la \n",
        "# actualización de los gradientes de los pesos. \n",
        "\n",
        "def nnCostFunction(nn_params,\n",
        "                   input_layer_size,\n",
        "                   hidden_layer_size,\n",
        "                   num_labels,\n",
        "                   X, y, lambda_=0.0):\n",
        "\n",
        "    # Reshape nn_params para obtener Theta1 y Theta2\n",
        "    Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n",
        "                        (hidden_layer_size, (input_layer_size + 1)))\n",
        "    Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n",
        "                        (num_labels, (hidden_layer_size + 1)))\n",
        "\n",
        "    m = y.size  # Número de ejemplos de entrenamiento\n",
        "\n",
        "    J = 0\n",
        "    Theta1_grad = np.zeros(Theta1.shape)\n",
        "    Theta2_grad = np.zeros(Theta2.shape)\n",
        "\n",
        "    # Propagación hacia adelante\n",
        "    a1 = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
        "    z2 = a1.dot(Theta1.T)\n",
        "    a2 = linear_activation(z2)\n",
        "    a2 = np.concatenate([np.ones((a2.shape[0], 1)), a2], axis=1)\n",
        "    z3 = a2.dot(Theta2.T)\n",
        "    a3 = linear_activation(z3)\n",
        "\n",
        "    # Asegurar que y tenga la forma adecuada\n",
        "    y = y.reshape(-1, 1)\n",
        "\n",
        "    #                Función de costo\n",
        "\n",
        "    #El término de regularización se añade al costo total para penalizar los valores grandes de los pesos. \n",
        "    # Esto ayuda a mantener los pesos pequeños, lo que generalmente conduce a un modelo menos complejo y más generalizable.\n",
        "    reg_term = (lambda_ / (2 * m)) * (np.sum(np.square(Theta1[:, 1:])) + np.sum(np.square(Theta2[:, 1:])))\n",
        "    J = (1 / (2 * m)) * np.sum(np.square(a3 - y))\n",
        "    J += reg_term\n",
        "\n",
        "    # Retropropagación\n",
        "    delta_3 = a3 - y\n",
        "    delta_2 = delta_3.dot(Theta2)[:, 1:] * linear_gradient(z2)\n",
        "\n",
        "    Delta1 = delta_2.T.dot(a1)\n",
        "    Delta2 = delta_3.T.dot(a2)\n",
        "\n",
        "    #                    Regularización de gradientes\n",
        "    # Esto se hace para asegurar que la penalización aplicada a los pesos a través de la función de costo se refleje también en la forma en que\n",
        "    # los gradientes ajustan estos pesos durante el entrenamiento.\n",
        "    Theta1_grad = (1 / m) * Delta1\n",
        "    Theta1_grad[:, 1:] += (lambda_ / m) * Theta1[:, 1:]\n",
        "    Theta2_grad = (1 / m) * Delta2\n",
        "    Theta2_grad[:, 1:] += (lambda_ / m) * Theta2[:, 1:]\n",
        "\n",
        "    # Desenrollar gradientes\n",
        "    grad = np.concatenate([Theta1_grad.ravel(), Theta2_grad.ravel()])\n",
        "\n",
        "    return J, grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "g1LN1-oV8bqg"
      },
      "outputs": [],
      "source": [
        "## Normalizacion de los datos\n",
        "\n",
        "\n",
        "#Al visualizar los datos se puede observar que las caracteristicas tienen diferentes magnitudes, por lo cual se debe transformar cada valor \n",
        "# en una escala de valores similares.\n",
        "\n",
        "def  featureNormalize(X):\n",
        "    X_norm = X.copy()\n",
        "\n",
        "    #creamos un array de ceros con una longitud igual al número de columnas en el array X. La variable mu y sigma se inicializa como este array de ceros.\n",
        "    mu = np.zeros(X.shape[1])\n",
        "    sigma = np.zeros(X.shape[1])\n",
        "\n",
        "    #Creamos el promedio de cada columna de X\n",
        "    mu = np.mean(X, axis = 0)\n",
        "    sigma = np.std(X, axis = 0)\n",
        "\n",
        "    sigma[sigma == 0] = 1\n",
        "\n",
        "    #normalizamos los datos con la siguiente formula\n",
        "    X_norm = (X - mu) / sigma\n",
        "\n",
        "    return X_norm, mu, sigma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XAuFRmmm8bqh"
      },
      "outputs": [],
      "source": [
        "X_norm, mu, sigma = featureNormalize(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L42PD6bQBPjm",
        "outputId": "74934a4f-b279-4bf2-ff7b-1117db49ddb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Longitud de nn_params: 191\n",
            "Expected size for Theta2: 6\n"
          ]
        }
      ],
      "source": [
        "print(\"Longitud de nn_params:\", len(nn_params))\n",
        "print(\"Expected size for Theta2:\", (hidden_layer_size + 1) * num_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onVWi9gF8bqh"
      },
      "source": [
        "## Calculo del costo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCAuNAW58bqh",
        "outputId": "0a21f194-3b92-47f9-8c82-9f50d47aff47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Costo en parametros (cargado de ex4weights): 96561263.968157 \n"
          ]
        }
      ],
      "source": [
        "lambda_ = 10000\n",
        "J, _ = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X_norm, y_train, lambda_)\n",
        "print('Costo en parametros (cargado de ex4weights): %.6f ' % J)\n",
        "#print('El costo debe esta cercano a               "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpdUGYU1awLO"
      },
      "source": [
        "## Inicializar pesos aleatorios\n",
        "\n",
        "\n",
        "\n",
        "La matriz de pesos inicializada aleatoriamente se devuelve como salida de la función."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CRznyU7Say8m"
      },
      "outputs": [],
      "source": [
        "#La función randInitializeWeights que has definido es un método común para inicializar los pesos de una red neuronal \n",
        "# de manera aleatoria. Esta inicialización es crucial para asegurar que la red neuronal comience el aprendizaje con una ruptura de simetría, \n",
        "# permitiendo que las neuronas aprendan diferentes funciones.\n",
        "\n",
        "def randInitializeWeights(L_in, L_out, epsilon_init=0.12):\n",
        "\n",
        "    W = np.zeros((L_out, 1 + L_in))\n",
        "    W = np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n",
        "\n",
        "    return W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcdyxL3ia6UO",
        "outputId": "61939931-e06b-4fd9-a7a4-18afb25660da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inicialización de parámetros de redes neuronales...\n"
          ]
        }
      ],
      "source": [
        "print('Inicialización de parámetros de redes neuronales...')\n",
        "\n",
        "initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)\n",
        "initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels)\n",
        "\n",
        "# Desenrrollr parametros\n",
        "initial_nn_params = np.concatenate([initial_Theta1.ravel(), initial_Theta2.ravel()], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ1CmxeXbBZm",
        "outputId": "2e61e47a-2d3a-4fda-a7d4-d65c4c296ee5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Manuel\\AppData\\Local\\Temp\\ipykernel_26108\\3311480215.py:17: OptimizeWarning: Unknown solver options: maxiter\n",
            "  res = optimize.minimize(costFunction,\n"
          ]
        }
      ],
      "source": [
        "## Calculo de Thetas\n",
        "\n",
        "# Después de haber completado la tarea, cambie el maxiter a uno más grande\n",
        "# Usando un numero maximo de iteraciones\n",
        "options= {'maxiter': 10000}\n",
        "\n",
        "# Tratamos con diferentes valores de lambda_\n",
        "lambda_ = 1\n",
        "\n",
        "# define una función anónima (lambda) llamada costFunction.\n",
        "costFunction = lambda p: nnCostFunction(p, input_layer_size,\n",
        "                                        hidden_layer_size,\n",
        "                                        num_labels, X_norm, y_train, lambda_)\n",
        "\n",
        "# Ahora, costFunction es una función que toma solo un argumento.\n",
        "# (los parámetros de la red neuronal)\n",
        "res = optimize.minimize(costFunction,\n",
        "                        initial_nn_params,\n",
        "                        jac=True,\n",
        "                        method='TNC',\n",
        "                        options=options)\n",
        "\n",
        "# obtenemos la solución de la optimización\n",
        "nn_params = res.x\n",
        "\n",
        "# Obtenemos Theta1 y Theta2 de nn_params\n",
        "Theta1 = np.reshape(nn_params[:hidden_layer_size * (input_layer_size + 1)],\n",
        "                    (hidden_layer_size, (input_layer_size + 1)))\n",
        "\n",
        "Theta2 = np.reshape(nn_params[(hidden_layer_size * (input_layer_size + 1)):],\n",
        "                    (num_labels, (hidden_layer_size + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsrvZ3kZexBI",
        "outputId": "96669ab7-0d10-4871-c1ea-0ec85afe4715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thetha 0 es:  [56.56180217  1.61536697  2.15792132  4.89687516  6.87190977 -2.59856486\n",
            " -5.3729668   6.36281569 -3.84303595  4.60398604  2.13071001 -5.25389563\n",
            "  4.19884523 11.10623418  4.05777811 10.15919757  0.23605694 -1.23052361\n",
            " -7.72623808  8.97728594 -0.08854751  9.05950888 -1.67402096 -0.16934777\n",
            "  0.36016393 -0.32746151  1.9959487   0.4489593  -0.9099932   1.89657482\n",
            " -8.9446574  -0.11210523 -2.2676405   1.05054947  2.08719331 -0.60323009\n",
            "  4.62120089]\n",
            "\n",
            "Thetha 1 es:  [14.3010542   0.17304808  0.21304453 -0.3169197  -2.67772884  0.42815104\n",
            "  0.75293362  2.02755037  0.60096107  2.5079373   1.69394782  0.59528476\n",
            "  0.93179615  4.37488259  4.51696587  4.90158757 -0.61145538  0.21419963\n",
            " -2.86365983  3.87592949 -0.67569465  1.9080532   0.15462704  0.70266865\n",
            "  1.83219796 -0.97312264 -0.21609617  1.73959228  0.41934263  1.01616504\n",
            " -2.55493863 -2.9159619  -2.4875912   2.23049507  0.83217668 -0.60039877\n",
            "  1.53673315]\n",
            "\n",
            "Thetha 2 es:  [22.10166466  0.37670532  0.6153139  -0.43380101 -4.08655779  0.70651763\n",
            "  0.81028186  3.38577134  0.5698934   3.80286303  2.56904697  0.81171006\n",
            "  1.75313269  6.89823092  7.06822063  7.02231395 -1.18878129  0.15683861\n",
            " -5.20279362  7.11759106 -1.29272363  3.30446803  0.17850259  1.01796802\n",
            "  2.18712792 -1.40093173 -0.22659475  2.36153917  0.66611994  1.46704714\n",
            " -3.94227885 -4.81232918 -3.81655872  3.34762055  1.37236455 -1.02477689\n",
            "  2.48360912]\n",
            "\n",
            "Thetha 3 es:  [-3.30371587e+01 -9.67833105e-01 -1.40002555e+00 -3.86536360e+00\n",
            " -6.40836482e+00  1.96930818e+00  4.13698097e+00 -3.47229076e+00\n",
            "  2.58670697e+00 -2.43660604e+00 -9.50919221e-01  3.52031918e+00\n",
            " -2.27870661e+00 -6.65360526e+00 -1.11544881e+00 -5.65397795e+00\n",
            " -2.99798619e-01  9.42897544e-01  4.40717252e+00 -4.87360695e+00\n",
            " -2.15533204e-01 -5.07959996e+00  1.28307443e+00  4.26184908e-01\n",
            "  2.90393499e-01  2.32096357e-02 -1.45528733e+00  1.10290773e-01\n",
            "  7.70979096e-01 -1.00605265e+00  5.71937187e+00 -9.80070435e-01\n",
            "  6.61013780e-01  1.57727601e-01 -1.06509680e+00  3.38333244e-02\n",
            " -2.79110768e+00]\n",
            "\n",
            "Thetha 4 es:  [-18.10820079  -0.22688769  -0.23586441   0.28556445   2.80824558\n",
            "  -0.28724687  -0.54819499  -2.1246907   -0.37687536  -2.48606306\n",
            "  -1.44471336  -0.46983809  -0.82615117  -4.04693374  -4.76881603\n",
            "  -5.10732807   0.57673587  -0.09327493   2.96518034  -3.66970015\n",
            "   0.67796449  -2.24076328  -0.17304352  -0.73781949  -1.57006036\n",
            "   0.93934162   0.14741372  -1.63697448  -0.38611534  -1.3059295\n",
            "   2.76019775   3.0883397    2.27243204  -1.9659129   -0.69113555\n",
            "   0.46676078  -1.5732472 ]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(Theta1)):\n",
        "    print(\"Thetha\",i,\"es: \", Theta1[i])\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQIUJ6rIfxi3",
        "outputId": "167a72b2-3bbd-4232-f8de-912828c3ba68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thetha 0 es:  [56.56180217  1.61536697  2.15792132  4.89687516  6.87190977 -2.59856486\n",
            " -5.3729668   6.36281569 -3.84303595  4.60398604  2.13071001 -5.25389563\n",
            "  4.19884523 11.10623418  4.05777811 10.15919757  0.23605694 -1.23052361\n",
            " -7.72623808  8.97728594 -0.08854751  9.05950888 -1.67402096 -0.16934777\n",
            "  0.36016393 -0.32746151  1.9959487   0.4489593  -0.9099932   1.89657482\n",
            " -8.9446574  -0.11210523 -2.2676405   1.05054947  2.08719331 -0.60323009\n",
            "  4.62120089]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(Theta2)):\n",
        "    print(\"Thetha\",i,\"es: \", Theta1[i])\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtG9YMHkq48R"
      },
      "source": [
        "## Funcion para realizar predicciones\n",
        "\n",
        "Predecir la salida de una entrada dada una red neuronal entrenada, Genera la salida prevista de X dados los pesos entrenados de un neural"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Yno4wwXgbeJ_"
      },
      "outputs": [],
      "source": [
        "def predict(Theta1, Theta2, X):\n",
        "\n",
        "    # Compute the output using the trained weights\n",
        "    h1 = np.dot(np.concatenate([np.ones((X.shape[0], 1)), X], axis=1), Theta1.T)\n",
        "    output = np.dot(np.concatenate([np.ones((h1.shape[0], 1)), h1], axis=1), Theta2.T)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVbdPMIhbpL-",
        "outputId": "18f2f347-babf-4ee8-da2c-f72ed595d9e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "las predicciones para los 6 ejemplos son:\n",
            "Para el ejemplo  1  es: [3981.90881353]\n",
            "\n",
            "Para el ejemplo  2  es: [3370.23393951]\n",
            "\n",
            "Para el ejemplo  3  es: [4844.32952875]\n",
            "\n",
            "Para el ejemplo  4  es: [4761.31698144]\n",
            "\n",
            "Para el ejemplo  5  es: [4076.08181451]\n",
            "\n",
            "Para el ejemplo  6  es: [4227.76716363]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Creamos la matriz con 6 ejemplos para hacer la prueba predecir un precio de cada ejemplo:\n",
        "matriz_datos = np.array([\n",
        "    [731.0, 9.0, 255.0, 0.604743080614, 0.999999993289, 0.79194630341, 4.9137254902, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.799755687423, 0.0500466753998, 0.0500962518137, 0.0501006734234, 0.0500007119405, 0.341245791246, 0.148947811448, 0.043137254902, 0.0156862745098, 0.733333333333, 0.266666666667, 0.286914600551, 0.0333333333333, 0.7, -0.11875, -0.125, -0.1, 0.0, 0.0, 0.5, 0.0], \n",
        "    [731.0, 9.0, 255.0, 0.604743080614, 0.999999993289, 0.79194630341, 4.9137254902, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.799755687423, 0.0500466753998, 0.0500962518137, 0.0501006734234, 0.0500007119405, 0.341245791246, 0.148947811448, 0.043137254902, 0.0156862745098, 0.733333333333, 0.266666666667, 0.286914600551, 0.0333333333333, 0.7, -0.11875, -0.125, -0.1, 0.0, 0.0, 0.5, 0.0], \n",
        "    [731.0, 13.0, 1072.0, 0.41564561695, 0.999999998565, 0.540889525766, 4.6828358209, 7.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0286328101715, 0.0287935517322, 0.0285751849112, 0.028571675324, 0.885426777861, 0.513502122877, 0.281003475691, 0.0746268656716, 0.0121268656716, 0.860215053763, 0.139784946237, 0.411127435065, 0.0333333333333, 1.0, -0.220192307692, -0.5, -0.05, 0.454545454545, 0.136363636364, 0.0454545454545, 0.136363636364], \n",
        "    [731.0, 13.0, 244.0, 0.559999997511, 0.999999993197, 0.680272104216, 4.42213114754, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.300293733076, 0.0500009756327, 0.0500010257644, 0.0500001760383, 0.549704089489, 0.331639928699, -0.0923054070113, 0.016393442623, 0.0245901639344, 0.4, 0.6, 0.292424242424, 0.136363636364, 0.433333333333, -0.456481481481, -1.0, -0.125, 0.7, -0.4, 0.2, 0.4], \n",
        "    [731.0, 11.0, 723.0, 0.490934448409, 0.999999997845, 0.642241377926, 5.22821576763, 6.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.866656685064, 0.0333372075669, 0.0333354827452, 0.0333356642467, 0.0333349603771, 0.375048678466, 0.182696038139, 0.0636237897649, 0.00829875518672, 0.884615384615, 0.115384615385, 0.340572181442, 0.0333333333333, 1.0, -0.213888888889, -0.6, -0.1, 0.5, 0.5, 0.0, 0.5], \n",
        "    [731.0, 14.0, 290.0, 0.611510789167, 0.999999994048, 0.76190475737, 4.06896551724, 9.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0222448007009, 0.306856235824, 0.0222310333686, 0.0222241628314, 0.626443767275, 0.571906729634, 0.31812180244, 0.0620689655172, 0.0103448275862, 0.857142857143, 0.142857142857, 0.438908128908, 0.136363636364, 1.0, -0.177777777778, -0.4, -0.00833333333333, 0.0, 0.0, 0.5, 0.0]\n",
        "])\n",
        "\n",
        "\n",
        "#Normalizamos todos\n",
        "matriz_datos= (matriz_datos - mu) / sigma\n",
        "\n",
        "\n",
        "#Calculamos la Y predicha de los 6 ejemplos de prediccion\n",
        "pred = predict(Theta1, Theta2, matriz_datos)\n",
        "\n",
        "print(\"las predicciones para los 6 ejemplos son:\")\n",
        "i = 0\n",
        "for i in range(len(matriz_datos)):\n",
        "    print(\"Para el ejemplo \",i+1,\" es:\", pred[i])\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jgogKAyrU9h"
      },
      "source": [
        "## Validaciones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "R3Z0tFDueRHX"
      },
      "outputs": [],
      "source": [
        "#Para hacer las validaciones correspondientes, primero se crea la funcion del **Mean squeared error**\n",
        "\n",
        "#haciendo calculo del error cuadratico medio:\n",
        "def mean_squared_error(y_pred, y_actual):\n",
        "    resta = y_pred - y_actual\n",
        "    err_cuadrado = np.sum(resta ** 2)\n",
        "    return err_cuadrado / len(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuawPjOSdPh3",
        "outputId": "5cd9d071-a9f0-4a32-cc31-ab3df3977b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2588.94320397]\n",
            " [2847.818122  ]\n",
            " [2038.10704569]\n",
            " ...\n",
            " [7269.97203949]\n",
            " [2010.42609237]\n",
            " [2236.40612303]]\n"
          ]
        }
      ],
      "source": [
        "# realiza la normalización de los datos de prueba\n",
        "X_test = (X_test - mu)/ sigma\n",
        "\n",
        "\n",
        "#Predicción Usando la Red Neuronal\n",
        "pred = predict(Theta1, Theta2, X_test)\n",
        "\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQptvnRdeWbu",
        "outputId": "9630c57e-b700-4a55-f839-518da97dbb0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error Cuadrático Medio (MSE) = 299343564954.9564\n",
            "Raíz del Error Cuadrático Medio (RMSE) = 547122.9888744911\n"
          ]
        }
      ],
      "source": [
        "mse = mean_squared_error(pred, y_test)\n",
        "#calculamos el error cuadratico medio:\n",
        "print('Error Cuadrático Medio (MSE) = ' + str(mse))\n",
        "print('Raíz del Error Cuadrático Medio (RMSE) = ' + str(np.sqrt(mse)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fV5x8wVrp8I"
      },
      "source": [
        "Concluciones\n",
        "\n",
        "R- Hecha las predicciones , se puede determinar que el modelo no reliza las predicciones exactas, esto debido a la diferencia entre el valor esperado y el calculado.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
